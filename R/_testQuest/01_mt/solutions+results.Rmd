---
title: "Solutions to mid-term exam (ds4psy)"
author: "Hansjörg Neth, SPDS, uni.kn"
date: "2018 06 25"
output:
   rmdformats::html_clean: # html_clean html_docco readthedown material #
     code_folding: show # hide
     toc_float: true
     toc_depth: 2
     highlight: kate # textmate default kate haddock monochrome #
     lightbox: true # true by default
     fig_width: 8 # in inches
editor_options: 
  chunk_output_type: console # inline
---

<!-- Collection of exercises and test problems | ds4psy: Summer 2018 -->

```{r preamble, echo = FALSE, eval = TRUE, cache = FALSE, message = FALSE, warning = FALSE}
## (a) Housekeeping: -----
rm(list=ls()) # clean all.

## (b) Current file name and path: ----- 
# cur.path <- dirname(rstudioapi::getActiveDocumentContext()$path)
# cur.path
# setwd(cur.path) # set to current directory
setwd("~/Desktop/stuff/Dropbox/_code/R/_teachR/ds4psy/R/_testQuest/01_mt") # set to current directory
# list.files() # all files + folders in current directory
fileName <- "solutions+results.Rmd"

## (c) Packages: ----- 
library(knitr)
library(rmdformats)
library(tidyverse)

## (d) Global options: ----- 
options(max.print = "75")
opts_chunk$set(echo = TRUE,
	             cache = TRUE,
               prompt = FALSE,
               tidy = FALSE,
               collapse = TRUE, # set TRUE in answers 
               comment = "#>",
               message = FALSE,
               warning = FALSE,
               ## Default figure options:
               fig.width = 8, 
               fig.asp = .618, # golden ratio
               out.width = "75%",
               fig.align = "center"
               )
opts_knit$set(width = 75)

## (e) Graphics: ----- 

# Defining colors:
seeblau <- rgb(0, 169, 224, names = "seeblau", maxColorValue = 255) # seeblau.4 (non-transparent)

seeblau.colors <- c(rgb(204, 238, 249, maxColorValue = 255), # seeblau.1
                    rgb(166, 225, 244, maxColorValue = 255), # seeblau.2 
                    rgb(89, 199, 235, maxColorValue = 255),  # seeblau.3
                    rgb(0, 169, 224, maxColorValue = 255),   # seeblau.4 
                    rgb(0, 0, 0, maxColorValue = 255),       #  5. black
                    gray(level = 0, alpha = .6),             #  6. gray 60% transparent
                    gray(level = 0, alpha = .4),             #  7. gray 40% transparent
                    gray(level = 0, alpha = .2),             #  8. gray 20% transparent
                    gray(level = 0, alpha = .1),             #  9. gray 10% transparent
                    rgb(255, 255, 255, maxColorValue = 255)  # 10. white
                    )

unikn.pal = data.frame(                             ## in one df (for the yarrr package): 
  "seeblau1" = rgb(204, 238, 249, maxColorValue = 255), #  1. seeblau1 (non-transparent)
  "seeblau2" = rgb(166, 225, 244, maxColorValue = 255), #  2. seeblau2 (non-transparent)
  "seeblau3" = rgb( 89, 199, 235, maxColorValue = 255), #  3. seeblau3 (non-transparent)
  "seeblau4" = rgb(  0, 169, 224, maxColorValue = 255), #  4. seeblau4 (= seeblau base color)
  "black"    = rgb(  0,   0,   0, maxColorValue = 255), #  5. black
  "seegrau4" = rgb(102, 102, 102, maxColorValue = 255), #  6. grey40 (non-transparent)
  "seegrau3" = rgb(153, 153, 153, maxColorValue = 255), #  7. grey60 (non-transparent)
  "seegrau2" = rgb(204, 204, 204, maxColorValue = 255), #  8. grey80 (non-transparent)
  "seegrau1" = rgb(229, 229, 229, maxColorValue = 255), #  9. grey90 (non-transparent)
  "white"    = rgb(255, 255, 255, maxColorValue = 255), # 10. white
  stringsAsFactors = FALSE)

## (f) Counters: ----- 
nr <- 0  # initialize task number
pt <- 0  # initialize point total
```

```{r utility_add_random_NA_values, echo = FALSE, eval = TRUE}
# Adding a random amount (number or proportion) of NA or other values to a vector:

## Function to replace a random amount of vector elements by NA values:  
add_NAs <- function(vec, amount){
  
  stopifnot((is.vector(vec)) & (amount >= 0) & (amount <= length(vec)))

  out <- vec
  n <- length(vec)
  
  amount2 <- ifelse(amount < 1, round(n * amount, 0), amount) # turn amount prop into n
  
  out[sample(x = 1:n, size = amount2, replace = FALSE)] <- NA
  
  return(out)

}

## Check:
# add_NAs(1:10, 0)
# add_NAs(1:10, 3)
# add_NAs(1:10, .5)
# add_NAs(letters[1:10], 3)

## Generalization: Replace a random amount of vector elements by what: 
add_whats <- function(vec, amount, what = NA){
  
  stopifnot((is.vector(vec)) & (amount >= 0) & (amount <= length(vec)))

  out <- vec
  n <- length(vec)
  
  amount2 <- ifelse(amount < 1, round(n * amount, 0), amount) # turn amount prop into n
  
  out[sample(x = 1:n, size = amount2, replace = FALSE)] <- what
  
  return(out)

}

## Check:
# add_whats(1:10, 3) # default: what = NA
# add_whats(1:10, 3, what = 99)
# add_whats(1:10, .5, what = "ABC")
```

# Introduction

This file contains possible solutions to the **mid-term exam** (on June 4, 2018). 

<!-- The following questions comprise our **mid-term exam** (on June 4, 2018). -->

This exam contains a total of **6 tasks** and a maximum score of **50 points**. 


## Course coordinates

<!-- uni.kn logo and link to SPDS: -->  
<!-- ![](./inst/pix/uniKn_logo.png) --> 
<a href="https://www.spds.uni-konstanz.de/">
<img src = "../../../inst/pix/uniKn_logo.png" alt = "spds.uni.kn" align = "right" width = "300" style = "width: 300px; float: right; border:20;"/>
<!-- <img src = "./inst/pix/uniKn_logo_s.png" alt = "spds.uni.kn" style = "float: right; border:20;"/> --> 
</a>

* Course [Data Science for Psychologists](http://rpository.com/ds4psy/) (ds4psy).  
* Taught at the [University of Konstanz](https://www.uni-konstanz.de/) by [Hansjörg Neth](http://neth.de/) (<h.neth@uni.kn>,  [SPDS](https://www.spds.uni-konstanz.de/), office D507).
* Spring/summer 2018: Mondays, 13:30--15:00, C511 (from 2018.04.16 to 2018.07.16) 
* Links to [ZeUS](https://zeus.uni-konstanz.de:443/hioserver/pages/startFlow.xhtml?_flowId=showEvent-flow&unitId=5101&termYear=2018&termTypeValueId=1&navigationPosition=hisinoneLehrorganisation,examEventOverviewOwn) and [Ilias](https://ilias.uni-konstanz.de/ilias/goto_ilias_uni_crs_758039.html)

## Preparation and response format

**`r nr`.** Please answer the following questions by creating a single R script (or an R-Markdown file `.Rmd`) that contains all your code and answers and meets the following criteria: 

- _Layout issues_: 

    1. Include a header that contains your _name_, _student ID_, this _course_, and today's _date_.
    
    2. Load the R packages of the `tidyverse`. 
    
    3. Structure your file clearly by _labeling_ the current task (e.g., `# Task 1: -----`) and subtask (e.g., `# (a) ...:`) and by _leaving blank lines_ between all tasks and subtasks. 
    
    Here's a layout template that you can copy and adapt: 

```{r layout_template, echo = TRUE, eval = FALSE}
## Mid-term exam  | Data science for psychologists (Summer 2018)
## Name: ... | Student ID: ...
## 2018 06 04
## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##

## Preparations: ----- 

library(tidyverse)


## Task 1: ----- 

## (a) Saving and inspecting data:
sp <- as_tibble(sleep)
dim(sp)

## Answer: The sleep data contains 20 rows and 3 columns. 

## (b): ... 
## ...


## Task X: ----- 
## (a) ...

## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
## End of file. ----- 
```

- Save your script (regularly) as `Lastname_Firstname_midTerm_180604.R` (replacing `Lastname` and `Firstname` by your names).

- When asked for numbers or interpretations, include _short answers as comments_ in your script. However, when asked for quantitative summaries containing more than 2 numbers (e.g., descriptive statistics of a dataset) simply print your results (e.g., the output of a `dplyr` pipe) in your code.

- Submit your script by email (as an attachment) to <h.neth@uni.kn> by 15:15 (today). 


# Task `r nr<-nr+1; nr`: Time to sleep

The `sleep` data (contained in R datasets) shows the effect of 2 sleep-promoting drugs (as an increase in hours of sleep compared to a control group) for 10 patients.

**`r nr`a.** Save the `sleep` data as a tibble `sp` and inspect its dimensions. (1&nbsp;point)  

**`r nr`b.** Use a `dplyr` pipe to compute the number of observations (rows) by group  
and key descriptives (their mean, median, and standard deviation). (2&nbsp;points) 

**`r nr`c.** Use `ggplot` to create a graph that shows the medians and raw values of `extra` sleep time by `group`. (2&nbsp;points)  

**Hints:** Use 2 different geoms to show both medians and raw values in the same plot. The order of layers is determined by the order of geom commands. 

**`r nr`d.** Reformat the `sleep` data in `sp` so that the 2 groups appear in 2 lines (rows) and 10 subject IDs as 10 columns. (1&nbsp;point)  

**Hints:** This implies using the `tidyr::spread` command to change a long dataset into a wider format.

```{r sleep, echo = TRUE, fig.show = "hold"}
# ?datasets::sleep

# (a) Save data as tibble and inspect:
sp <- as_tibble(sleep)
sp # => 20 cases (rows) x 3 variables (columns)

# (b) Compute the number of observations and descriptives of extra time by group:
sp %>% 
  group_by(group) %>%
  summarize(n = n(),
            md = median(extra),
            mn = mean(extra),
            sd = sd(extra))

# (c) Visualize the raw values and averages by group:
ggplot(sp, aes(x = group, y = extra)) +
  geom_boxplot(aes(fill = group)) +
  # geom_violin() +
  geom_point(aes(shape = group), size = 4, alpha = 2/3, position = "jitter") + 
  ## Pimping plot: 
  labs(title = "Extra sleep time by treatment group", 
       x = "Treatment group", y = "Extra sleep time", 
       caption = "Data from datasets::sleep.") + 
  scale_fill_manual(values = c("gold1", "steelblue3")) +
  theme_bw()

# (d) Reformat data so that the 2 groups appear in 2 lines, 
#     and 10 subject IDs as 10 columns:
sp %>%
  spread(key = ID, value = extra)

pt <- pt + 6  # increment point total
```


# Task `r nr<-nr+1; nr`: Party plots

The following table provides the percentage share of 2 major parties on the last 2 
general elections of Germany (based on [this link](https://www.bundeswahlleiter.de/info/presse/mitteilungen/bundestagswahl-2017/34_17_endgueltiges_ergebnis.html)):

| Party:  | Share 2013:       | Share 2017:       |
|:------- |--------:|--------:|
| CDU/CSU | `r (34.1 + 7.4)`% | `r (26.8 + 6.2)`% |
| SPD     | `r (25.7)`%       | `r (20.5)`%       |
| Others  |      `?`          |    `?`            | 

<!-- Details: from 
https://www.bundeswahlleiter.de/info/presse/mitteilungen/bundestagswahl-2017/34_17_endgueltiges_ergebnis.html 

CDU 	Christlich Demokratische Union Deutschlands 	26,8 % 	(2013: 34,1 %)
SPD 	Sozialdemokratische Partei Deutschlands 	    20,5 % 	(2013: 25,7 %)
AfD 	Alternative für Deutschland 	                12,6 % 	(2013:  4,7 %)
FDP 	Freie Demokratische Partei 	                  10,7 % 	(2013:  4,8 %)
DIE LINKE 	DIE LINKE 	                             9,2 % 	(2013:  8,6 %)
GRÜNE 	    BÜNDNIS 90/GRÜNE 	                       8,9 % 	(2013:  8,4 %)
CSU 	Christlich-Soziale Union in Bayern e.V 	       6,2 % 	(2013:  7,4 %)
Sonstige 	  	                                       5,0 % 	(2013:  6,2 %)

--> 

**`r nr`a.** Create a tibble `de` that contains this data and the missing (`?`) values for all other parties so that all shares of an election add up to 100%. (2&nbsp;points)  

**`r nr`b.** Convert your `de` table into a "tidy" table saved as `de_2`. (2&nbsp;points)  

**Hints:** Use `tidyr::gather` to list the values of all election results in 1 variable called `share` and make sure that `de_2` contains a separate variable (column) that specifies the election `year`.

**`r nr`c.** Visualize and contrast the election results by a bar chart that contains 2 bars (representing the 2 elections) and the party's share of votes (as the proportions of each bar). (2&nbsp;points)  

**Hints:** As the data in `de_2` already contains the identity of the values which you want to plot, there is no need to count anything. Showing multiple values in one bar is called a "stack".

```{r election_results, fig.show = "hold"}
## (a) Create a tibble with the data:
de <- tibble(
    party = c("CDU/CSU", "SPD", "Others"),
    share_2013 = c((.341 + .074), .257, (1 - (.341 + .074) - .257)), 
    share_2017 = c((.268 + .062), .205, (1 - (.268 + .062) - .205))
  )
de$party <- factor(de$party, levels = c("CDU/CSU", "SPD", "Others"))  # optional
de

## Check that columns add to 100:
sum(de$share_2013)  # => 1 (qed)
sum(de$share_2017)  # => 1 (qed)

## (b) Converting de into a tidy data table:
de_2 <- de %>%
  gather(share_2013:share_2017, key = "election", value = "share") %>%
  separate(col = "election", into = c("dummy", "year")) %>%
  select(year, party, share)
de_2

## Note that year is of type character, which could be changed by:
# de_2$year <- parse_integer(de_2$year)

## (c) Bar chart showing proportions for each election:
ggplot(de_2, aes(x = year, y = share, fill = party)) +
  ## (A) 1 bar per election (position = "stack"):
  geom_bar(stat = "identity", position = "stack") +  # 1 bar per election
  ## (B) 3 bars per election (position = "dodge"):  
  # geom_bar(stat = "identity", position = "dodge") +  # 3 bars next to each other
  ## Pimping plot: 
  scale_fill_manual(values = c("black", "red3", "gold")) + # optional
  labs(title = "Partial results of the German general elections 2013 and 2017", 
       x = "Year of election", y = "Share of votes", 
       caption = "Data from www.bundeswahlleiter.de.") +
  theme_classic()

pt <- pt + 6  # increment point total
```


# Task `r nr<-nr+1; nr`: R wars

Let's tackle the universe with the tidyverse by uncovering some facts about the `dplyr::starwars` dataset. Answer the following questions by using pipes of basic `dplyr` commands (i.e., arranging, filtering, selecting, grouping, counting, summarizing). 

**`r nr`a.** Save the tibble `dplyr::starwars` as `sw` and report its dimensions. (1&nbsp;point)  

**`r nr`b.** Missing values and known unknowns:

- How many missing (`NA`) values does `sw` contain? (1&nbsp;point)  

- Which individuals come from an unknown (missing) `homeworld` but have a known `birth_year` or known `mass`? (1&nbsp;point)

<!-- Which variable (column) has the most missing values? --> 

<!-- Replace all missing values of `hair_color` (in the variable `sw$hair_color`) by "bald". (2&nbsp;points)  -->


**`r nr`c.** Gender issues:

- How many humans are contained in `sw` overall and by gender? (1&nbsp;point)

- How many and which individuals in `sw` are neither male nor female? (1&nbsp;point)

- Of which species in `sw` exist at least 2 different gender values? (1&nbsp;point)


**`r nr`d.** Popular homes and heights:

- From which `homeworld` do the most indidividuals (rows) come from? (1&nbsp;point)

- What is the mean `height` of all individuals with orange eyes from the most popular homeworld? (1&nbsp;point)


**`r nr`e.** Seize and mass issues: 

- Compute the median, mean, and standard deviation of `height` for all droids. (1&nbsp;point) 

- Compute the average height and mass by species and save the result as `h_m`. (1&nbsp;point) 

- Sort `h_m` to list the 3 species with the smallest individuals (in terms of mean height). (1&nbsp;point) 

- Sort `h_m` to list the 3 species with the heaviest individuals (in terms of median mass). (1&nbsp;point) 

```{r, starwars_transformations}
# library(tidyverse)
# ?dplyr::starwars

## (a) Basic data properties: ---- 
sw <- dplyr::starwars
dim(sw)  # => 87 rows (denoting individuals) x 13 columns (variables) 

## Missing data: ----- 

## (+) How many missing data points?
sum(is.na(sw))  # => 101 missing values.

# (+) Which individuals come from an unknown (missing) homeworld 
#     but have a known birth_year or mass? 
sw %>% 
  filter(is.na(homeworld), !is.na(mass) | !is.na(birth_year))


## (x) Which variable (column) has the most missing values?
colSums(is.na(sw))  # => birth_year has 44 missing values
colMeans(is.na(sw)) #    (amounting to 50.1% of all cases). 

## (x) Replace all missing values of `hair_color` (in the variable `sw$hair_color`) by "bald": 
# sw$hair_color[is.na(sw$hair_color)] <- "bald"


## (c) Gender issues: ----- 

# (+) How many humans are there of each gender?
sw %>% 
  filter(species == "Human") %>%
  group_by(gender) %>%
  count()

## Answer: 35 Humans in total: 9 females, 26 male.

# (+) How many and which individuals are neither male nor female?
sw %>% 
  filter(gender != "male", gender != "female")

# (+) Of which species are there at least 2 different gender values?
sw %>%
  group_by(species, gender) %>%
  count() %>%  # table shows species by gender: 
  group_by(species) %>%  # Which species appear more than once in this table? 
  count() %>%
  filter(nn > 1)

# alternative (and shorter) solution:
sw %>%
  group_by(species)%>%
  summarise(n_gender_vals = n_distinct(gender)) %>%
  filter(n_gender_vals >= 2)

## (d) Homeworld issues: ----- 

# (+) Popular homes: From which homeworld do the most indidividuals (rows) come from? 
sw %>%
  group_by(homeworld) %>%
  count() %>%
  arrange(desc(n))
# => Naboo (with 11 individuals)

# (+) What is the mean height of all individuals with orange eyes from the most popular homeworld? 
sw %>% 
  filter(homeworld == "Naboo", eye_color == "orange") %>%
  summarise(n = n(),
            mn_height = mean(height))

## Note: 
sw %>% 
  filter(eye_color == "orange") # => 8 individuals


# (+) What is the mass and homeworld of the smallest droid?
sw %>% 
  filter(species == "Droid") %>%
  arrange(height)

## (4) Group summaries: ----- 

# (+) Compute the median, mean, and standard deviation of `height` for all droids.
sw %>%
  filter(species == "Droid") %>%
  summarise(n = n(),
            not_NA_h = sum(!is.na(height)),
            md_height = median(height, na.rm = TRUE),
            mn_height = mean(height, na.rm = TRUE),
            sd_height = sd(height, na.rm = TRUE))

# (+) Compute the average height and mass by species and save the result as `h_m`:
h_m <- sw %>%
  group_by(species) %>%
  summarise(n = n(),
            not_NA_h = sum(!is.na(height)),
            mn_height = mean(height, na.rm = TRUE),
            not_NA_m = sum(!is.na(mass)),
            md_mass = median(mass, na.rm = TRUE)
            )
h_m

# (+) Use `h_m` to list the 3 species with the smallest individuals (in terms of mean height)?
h_m %>% arrange(mn_height) %>% slice(1:3)

# (+) Use `h_m` to list the 3 species with the heaviest individuals (in terms of median mass)?
h_m %>% arrange(desc(md_mass)) %>%  slice(1:3)

pt <- pt + 12  # increment point total
```


# Task `r nr<-nr+1; nr`: Taking stocks 

```{r stock_data_definition, echo = FALSE, eval = TRUE}
# Define the stock data (to be shown below) as a tibble: 
st <- tribble(
  ~stock, ~d1_start, ~d1_end, ~d2_start, ~d2_end, ~d3_start, ~d3_end,  
  #-----|----------|--------|----------|--------|----------|--------|
  "Amada",   2.5,     3.6,    3.5,       4.2,      4.4,       2.8,            
  "Betix",   3.3,     2.9,    3.0,       2.1,      2.3,       2.5,  
  "Cevis",   4.2,     4.8,    4.6,       3.1,      3.2,       3.7     
)
```

The following table shows the start and end price of 3 stocks on 3 days (d1, d2, d3):

```{r stock_data_table, echo = FALSE, eval = TRUE}
knitr::kable(st, caption = "Stock data example showing the start and end prices of the shares of 3 companies on 3 days.")
```

<!-- Data as Rmd table in text: 
| stock  | d1_start | d1_end | d2_start | d2_end | d3_start | d3_end |  
|---------|---------|--------|----------|--------|----------|--------|
| "Amada" |   2.5  |   3.6   |   3.5    |  4.2   |   4.4    |   2.8  |            
| "Betix" |   3.3  |   2.9   |   3.0    |  2.1   |   2.3    |   2.5  |  
| "Cevis" |   4.2  |   4.8   |   4.6    |  3.1   |   3.2    |   3.7  |
--> 

**`r nr`a.** Create a tibble `st` that contains this data in this (wide) format. (1&nbsp;point)  

**`r nr`b.** Transform `st` into a longer table `st_long` that contains 18 rows and only 1 numeric variable for all stock prices. Adjust this table so that the `day` and `time` appear as 2 separate columns. (2&nbsp;points)  

**`r nr`c.** Create a graph that shows the 3 stocks' `end` prices (on the y-axis) over the 3 days (on the x-axis). (1&nbsp;point) 

**`r nr`d.** Spread  `st_long` into a wider table that contains `start` and `end` prices as 2 distinct variables (columns) for each stock and day. (1&nbsp;point) 

```{r stock_solution, echo = TRUE, fig.show = "hold"}
# library(tidyverse)

## (a) Enter stock data (in wide format) as a tibble:
st <- tribble(
  ~stock, ~d1_start, ~d1_end, ~d2_start, ~d2_end, ~d3_start, ~d3_end,  
  #-----|----------|--------|----------|--------|----------|--------|
  "Amada",   2.5,     3.6,    3.5,       4.2,      4.4,       2.8,            
  "Betix",   3.3,     2.9,    3.0,       2.1,      2.3,       2.5,  
  "Cevis",   4.2,     4.8,    4.6,       3.1,      3.2,       3.7     
)
dim(st)

## Note data structure: 
## 2 nested factors: day (1 to 3), type (start or end).

## (b) Change from wide to long format 
##     that contains the day (d1, d2, d3) and type (start vs. end) as separate columns:
st_long <- st %>%
  gather(d1_start:d3_end, key = "key", value = "val") %>%
  separate(key, into = c("day", "time")) %>%
  arrange(stock, day, time) # optional: arrange rows
st_long

## (c) Plot the end values (on the y-axis) of the 3 stocks over 3 days (x-axis):
st_long %>% 
  filter(time == "end") %>%
  ggplot(aes(x = day, y = val, color = stock, shape = stock)) +
  geom_point(size = 4) + 
  geom_line(aes(group = stock)) +
  ## Pimping plot: 
  labs(title = "End prices of stocks", 
       x = "Day", y = "End price", 
       shape = "Stock:", color = "Stock:") +
  theme_bw()

## (d) Change st_long into a wider format that lists start and end as 2 distinct variables (columns):
st_long %>%
  spread(key = time, value = val) %>%
  mutate(day_nr = parse_integer(str_sub(day, 2, 2))) # optional: get day_nr as integer variable
 
pt <- pt + 5  # increment point total
```


# Task `r nr<-nr+1; nr`: Flower power

The `iris` data (contained in R datasets) provides the measurements (in cm) of plant parts (length and width of _sepal_ and _petal_ parts) for 50 flowers from each of 3 species of iris (called _setosa_, _versicolor_, and _virginica_).

<!-- Exploratory data analysis (EDA): --> 

**`r nr`a.** Save `datasets::iris` a tibble `ir` that contains this data and inspect it. 
Are there any missing values? (2&nbsp;points)  

**`r nr`b.** Compute a summary table that shows the means of the 4 measurement columns (`Sepal.Length`, `Sepal.Width`, `Petal.Length`, `Petal.Width`) for each of the 3 `Species` (in rows). 
Save the resulting table of means as a tibble `im1` . (2&nbsp;points) 

**`r nr`c.** Create a histogram that shows the distribution of `Sepal.Width` values 
across all species. (1&nbsp;point)  

**`r nr`d.** Create a plot that shows the shape of the distribution of `Sepal.Width` values for each species. (1&nbsp;point)  

**`r nr`e.** Create a plot that shows `Petal.Width` as a function of `Sepal.Width` 
separately (i.e., in 3 facets) for each species. (1&nbsp;point)  

```{r iris_EDA, fig.show = "asis"}
# ?iris

## (a) Turn into tibble and inspect: ----- 
ir <- as_tibble(datasets::iris)
dim(ir)        # => 150 observations (rows) x 5 variables (columns)
sum(is.na(ir)) # =>   0 missing values

## (b) Compute counts and means by species: ----- 
im1 <- ir %>%
  group_by(Species) %>%
  summarise(n = n(),
            mn_sep.len = mean(Sepal.Length),
            mn_sep.wid = mean(Sepal.Width),
            mn_pet.len = mean(Petal.Length),
            mn_pet.wid = mean(Petal.Width)
            )

# Print im1 (as table with 4 variables of means): 
knitr::kable(im1, caption = "Average iris measures (4 variables of mean values).") 

## Graphical exploration: ----- 

## Distribution of 1 (continuous) variable:

## (c) Distribution of Sepal.Width across species:
ggplot(ir, aes(x = Sepal.Width)) +
  geom_histogram(binwidth = .1, fill = "forestgreen") + 
  labs(title = "Distribution of sepal width across iris species") +
  theme_bw()

## Distributions/relationships between 2 variables (1 categorical, 1 continuous):

## (d) The distributions of Sepal.Width by species:
ggplot(ir, aes(x = Species, y = Sepal.Width, fill = Species, shape = Species)) +
  geom_violin() +
  geom_point(size = 4, alpha = 1/2, position = "jitter") +
  labs(title = "Distributions of sepal width by iris species") +
  theme_bw()

## Alternative solution using density plots: 
ggplot(ir, aes(x = Sepal.Width, fill = Species)) +
  facet_wrap(~Species) + 
  geom_density() +
  labs(title = "Distributions of sepal width by iris species") + 
  coord_fixed() +
  theme_bw()

## Relationships between 2 variables (2 continuous):

## (e) Petal.Width as a function of Sepal.Width by iris species: 
ggplot(ir, aes(x = Sepal.Width, y = Petal.Width, color = Species, shape = Species)) +
  facet_wrap(~Species) +
  geom_jitter(size = 3, alpha = 2/3) +
  # geom_density2d() +
  coord_fixed() +
  labs(title = "Petal width as a function of sepal width by iris species") +
  theme_bw()

pt <- pt + 7  # increment point total

## next: Turn iris df into long format using tidyr::gather ----- 
## (see below)
```

<!-- Tidy data --> 

**`r nr`f.** Re-format your tibble `ir` into a tibble `ir_long` which in "long format". (2&nbsp;points)  

**Hint:** Use `tidyr::gather` and `separate` to turn `ir` into a tibble that contains only 1 dependent variable for the value of measurements (e.g., `val`), but 2 categorical variables that specify the `part` (Sepal vs. Petal) and `metric` (Length vs. Width) of each observation.


**`r nr`g.** Use `ir_long` to recompute the subgroup means (for each combination of species, plant part, and metric) computed in **`r nr`b.**.  Save the resulting table of means as a tibble `im2` and verify that they have not changed from `im1` above. (2&nbsp;points)  


**`r nr`h.** Visualize the relationships between the means of `im2` (i.e., the mean measurements by plant part and metric) separately for each species. (2&nbsp;points)  

**Hints:** This task asks for showing the value of a continuous variable (the value of means) as a function of 2 categorical variables (the plant `part` and type of `metric`). Possible solutions could incorporate either `geom_line` or `geom_tile` and use different facets for different `Species`. 


**`r nr`i.** **Bonus task:** Re-format your tibble `ir_long` (in long format) into a wider tibble `ir_short` that corresponds to the original `ir` dataset. (2&nbsp;bonus points)  

**Hints:** This task calls for applying `tidyr::spread` and `unite` commands to `ir_long`. 
However, `spread` will encounter an error unless every individual plant is identified by a unique variable (e.g., `id` number). This can be achieved by adding a numeric counter variable `id` (with values of `rep(1:50, 3)`) to `ir` _before_ creating `ir_long`. 

```{r iris_tidyr}
## Data (from above): 
# ?iris
# ir <- as_tibble(datasets::iris)
# ir

## (f) Re-format ir into long format (using tidyr::gather) ----- 
ir_long <- ir %>% 
  mutate(id = rep(1:50, 3)) %>%   # add a unique id to each plant [to enable (i) below]
  gather(Sepal.Length:Petal.Width, key = "type", value = "val") %>%
  separate("type", into = c("part", "metric"), sep = "\\.")

ir_long
dim(ir_long) # => 600 rows x 5 columns

## (g) Recompute group counts and means from ir_long: ----- 
im2 <- ir_long %>%
  group_by(Species, part, metric) %>%
  summarise(n = n(),
            mn_val = mean(val)
            )

# Print im2 (as table with 4 variables of means): 
knitr::kable(im2, caption = "Average iris measures (1 variable of mean values).")

## Check: Compare sums of all means in im1 vs. im2: 
sum1 <- sum(im1$mn_sep.len) + sum(im1$mn_sep.wid) + 
        sum(im1$mn_pet.len) + sum(im1$mn_pet.wid)  # => 41.574
sum2 <- sum(im2$mn_val)  # => 41.574
sum1 == sum2             # => TRUE (qed)


## Showing the value of a continuous variable by 2 categorical variables: ----- 

## (h) Visualize the means of im2 (i.e., mean measurements by plant part and metric) 
##     as a line plot separately for each species:
ggplot(im2, aes(x = part, y = mn_val, group = metric, color = metric)) +
  facet_wrap(~Species) +
  geom_point(aes(shape = metric), size = 3) +
  geom_line(aes(linetype = metric)) +
  labs(title = "Mean petal and sepal lengths and widths by iris species") + 
  theme_bw()

## Alternative solution using tile plots:
ggplot(im2, aes(x = part, y = metric)) +
  facet_wrap(~Species) +
  geom_tile(aes(fill = mn_val)) +
  geom_text(aes(label = mn_val), color = "white") + 
  labs(title = "Mean petal and sepal lengths and widths by iris species") + 
  theme_bw()

## Alternative: Using raw values (ir_long) to visualize the distributions 
##              of val as a function of Species, plant part, and metric:
ggplot(ir_long, aes(x = part, y = val, fill = Species)) + 
  facet_wrap(~Species) +
  geom_violin() +
  geom_jitter(aes(shape = metric), size = 2, alpha = 2/3) + 
  labs(title = "Mean petal and sepal lengths and widths by iris species") + 
  theme_bw()

## (i) Bonus task: ----- 

## See (f) above for the additional id-column for each plant:
## mutate(id = rep(1:50, 3)) %>% ...

## Re-format ir_long into shorter format (using tidyr::spread) ----- 
ir_short <- ir_long %>%
  unite(type, part, metric, sep = ".") %>%  # unite part and metric into "type" column
  spread(key = type, value = val) %>%       # spread "type" variable into multiple columns
  arrange(Species, id)

ir_short

## Verify identity of all measurement values in ir and ir_short: 
all.equal(ir$Sepal.Length, ir_short$Sepal.Length) & 
all.equal(ir$Sepal.Width,  ir_short$Sepal.Width)  &
all.equal(ir$Petal.Length, ir_short$Petal.Length) & 
all.equal(ir$Petal.Width,  ir_short$Petal.Width)  # => TRUE (qed) 

pt <- pt + (6 + 0)  # increment point total (leaving out 2 bonus points) 
```


# Task `r nr<-nr+1; nr`: Not all outliers are alike 

This task examines the statistical definition of outliers and uses a generated dataset (entitled `out.csv` and available at <http://rpository.com/ds4psy/mt/out.csv>). Use the following `read_csv()` command to obtain and load it into R: 

```{r outlier_load_data, echo = TRUE, eval = TRUE}
## Load data (as comma-separated file): 
data <- read_csv("http://rpository.com/ds4psy/mt/out.csv")  # from online source

## Alternatively (from local source): 
# data <- read_csv("out.csv")  # from current directory
```

An _outlier_ can be defined as an individual whose value in some metric deviates by more than a given criterion (e.g., 2 standard deviations) from the mean. But this definition is incomplete unless it also specifies an appropriate reference group. This task explores the implications of different reference groups. 

```{r outlier_create_data, echo = FALSE, eval = FALSE}
# library(tidyverse)

## Creating a suitable data set: 
set.seed(123)
n <- 1000
id <- paste0("nr.", 1:n) # paste0(sample(LETTERS, 1), sample(LETTERS, 1))
sex <- sample(x = c(0, 1), size = n, replace = TRUE)
height <- rep(NA, n)
noise_0 <- round(rnorm(n, mean = 0, sd = 8), 0)
noise_1 <- round(rnorm(n, mean = 0, sd = 11), 0)
height[sex == 0] <- 169 + noise_0[sex == 0]
height[sex == 1] <- 181 + noise_1[sex == 1]

## Modify data:
height <- add_NAs(height, amount = 18)  # 1.8% NA values in height
height[sex == 0] <- add_whats(vec = height[sex == 0], amount = 1, what = 202) # add a tall woman
# sex <- add_NAs(sex, amount = 3)          # 2  NA values in sex

## Save data as tibble: 
data <- as_tibble(data_frame(id, sex, height))
data$sex <- factor(data$sex, labels = c("female", "male"))
names(data) <- c("id", "sex", "height")

## Check data:
mean(data$sex == "female", na.rm = TRUE)  # => .507
mean(data$height, na.rm = TRUE)           # => 174.7006 (with seed 123)

## Writing out data:
write_csv(data, "out.csv")

## Reading in again (from csv-file):
data <- read_csv("out.csv")
data
```

**`r nr`a.** Save the data into a tibble `data` and report its number of observations and variables. (1&nbsp;point)   

**`r nr`b.** How many missing data values are there in `data`? (1&nbsp;point) 

**`r nr`c.** What is the gender (or `sex`) distribution in this sample? (1&nbsp;point)  

**`r nr`d.** Create a plot that shows the distribution of `height` values for each gender. (1&nbsp;point) 

<!-- Definition: Outlier -->

**`r nr`e.** Compute 2 new variables that signal and distinguish between 2 types of outliers in terms of `height`: 

1. outliers relative to the `height` of the _overall sample_ 
(i.e., individuals with `height` values deviating more than 2 SD from the overall mean of `height`) (1&nbsp;point);

2. outliers relative to the `height` of _some subgroup_'s mean and SD. Here, a suitable subgroup to consider is every person's gender 
(i.e., individuals with `height` values deviating more than 2 SD from the mean `height` of their own gender). (1&nbsp;point) 

**Hints:** As both variable signal whether or not someone is an outlier they should be defined as logicals (being either `TRUE` or `FALSE`) and added as new columns to `data` (via appropriate `mutate` commands). While the 1st variable can be computed based on the mean and SD of the overall sample, the 2nd variable can be computed after grouping `data` by gender and then computing and using the corresponding mean and SD values. The absolute difference between 2 numeric values `x` and `y` is provided by `abs(x - y)`. 

**`r nr`f.** Use the 2 new variables to define and identify 2 subgroups of people: 

1. `out_1`: Individuals (females and males) with `height` values that are outliers relative to _both_ the entire sample _and_ the sample of their own gender. How many such individuals are in `data`? (1&nbsp;point) 

2. `out_2`: Individuals (females and males) with `height` values that are _not_ outliers relative to the entire population, but _are_ outliers relative to their own gender. How many such individuals are in `data`? (1&nbsp;point) 

**`r nr`g.** **Bonus task:** Visualize the raw values and distributions of `height` for both types of outliers (`out_1` and `out_2`) in 2 separate plots and describe the `height` and `sex` combination of the individuals shown in each plot. (2&nbsp;bonus points)  

<!-- fig.show options: "asis", "hide", "hold", "animate" --> 

```{r outlier_solution, fig.show = "asis"}
## (a) Load and inspect data:
# data <- read_csv("out.csv") # read in csv-file
# data <- as_tibble(data)   # if data is not already a tibble
dim(data)  # => 1000 observations (rows) x 3 variables (columns)

## (b) Missing data points: 
sum(is.na(data))  # => 18 missing values

## (c) Gender distribution: 
data %>% 
  group_by(sex) %>% 
  count()
# => 50.7% females, 49.3% males.

## (d) Distributions of `height` as density plot: 
ggplot(data, aes(x = height)) +
  geom_density(fill = "gold", alpha = 2/3) +
  geom_density(aes(fill = sex), alpha = 2/5) +
  labs(title = "Distribution of heights overall and by gender", 
       fill = "Gender") + 
  scale_fill_manual(values = c("firebrick", "steelblue3")) +
  theme_bw()

# Note: To avoid the Warning about removing 18 cases with NA-values, 
#       we could first filter out those cases:
# non_NA_data <- filter(data, !is.na(height))

## Alternative solution as 2 histograms: 
ggplot(data) +
  facet_wrap(~sex) + 
  geom_histogram(aes(x = height, fill = sex), binwidth = 5, color = "grey10") +
  labs(title = "Distribution of heights by gender",
       fill = "Gender") +
  scale_fill_manual(values = c("firebrick", "steelblue3")) +
  theme_bw()

## (+) Included in (e), but also possible to do separately:  
##     Compute the number, means and SD of height values in 2 ways: 
{
  ## 1. overall: 
  data %>%
    summarise(n = n(),
              n_not_NA = sum(!is.na(height)),
              mn_height = mean(height, na.rm = TRUE),
              sd_height = sd(height, na.rm = TRUE))
  
  ## 2. by gender:
  data %>%
    group_by(sex) %>%
    summarise(n = n(),
              n_not_NA = sum(!is.na(height)),
              mn_height = mean(height, na.rm = TRUE),
              sd_height = sd(height, na.rm = TRUE))
  }


## (e) Detecting and marking outliers (by logical variables): ----- 

## Compute the means, SDs, and corresponding outliers in 2 ways:

crit <- 2  # criterion value for detecting outliers (in SD units)

data_out <- data %>%      
  # 1. Compute means, SD, and outliers for overall sample: 
  mutate(mn_height  = mean(height, na.rm = TRUE),  
         sd_height  = sd(height, na.rm = TRUE),
         out_height = abs(height - mn_height) > (crit * sd_height)) %>%
  group_by(sex) %>%       
  # 2. Compute same metrics for subgroups (by sex):
  mutate(mn_sex_height  = mean(height, na.rm = TRUE), 
         sd_sex_height  = sd(height, na.rm = TRUE),
         out_sex_height = abs(height - mn_sex_height) > (crit * sd_sex_height))

# data_out

## (f) Identify 2 types of outliers: ----- 

## 1. Outliers relative to the entire population AND to their own gender: 
out_1 <- data_out %>%
  filter(out_height & out_sex_height) %>%
  arrange(sex, height)

nrow(out_1) # => 21 individuals. 

## 2. Outliers relative to their own gender, but NOT relative to the entire population:
out_2 <- data_out %>%
  filter(!out_height & out_sex_height) %>%
  arrange(sex, height)  

nrow(out_2) # => 24 individuals.


## (g) Bonus task:  
## Visualization and interpretation of both types of outliers: ----- 

## 1. Showing out_1: 
ggplot(out_1, aes(x = sex, y = height)) +
  geom_violin(aes(fill = sex)) + 
  geom_jitter(size = 4, alpha = 2/3) + 
  scale_fill_manual(values = c("firebrick", "steelblue3")) +
  labs(title = "Outliers relative to both overall sample and gender", 
       x = "Gender", y = "Height (in cm)", 
       fill = "Gender:") +
  theme_bw()

# Interpretation: 
# `out_1` contains mostly short women (except for 1 tall woman) 
#  and mostly tall men (except for 2 short men). 

## 2. Showing out_2: 
ggplot(out_2, aes(x = sex, y = height)) +
  geom_violin(aes(fill = sex)) + 
  geom_jitter(size = 4, alpha = 2/3) + 
  scale_fill_manual(values = c("firebrick", "steelblue3")) +
  labs(title = "Outliers relative to gender but not overall sample", 
       x = "Gender", y = "Height (in cm)", 
       fill = "Gender:") +
  theme_bw()

# Interpretation: 
# `out_2` contains individuals which are either tall women or short men.

pt <- pt + (8 + 0)  # increment point total (leaving out 2 bonus points)
```

## Counting tasks and points 

This exam contains **`r nr` tasks** for a total of **`r pt` points** (plus 4 possible bonus points). 

# Results

The following plots summarize the total points achieved (on June 4, 2018) and corresponding grades: 

```{r mt_results, echo = FALSE, eval = TRUE}
# Results: 
pts <- c(38, 7, 21, 24, 14, 33, 37, 18, 11, 26, 22, 46, 41)
length(pts)
summary(pts)

thresholds <- c(seq(0, 35, by = 5), 50)
thresholds
length(thresholds)
grade_scale = c(3.3, 3.0, 2.7, 2.3, 2.0, 1.7, 1.3, 1.0)
length(grade_scale)

grade <- cut(x = pts, breaks = thresholds, labels = grade_scale)
grade

# as tibble:
results <- tibble(pts = pts, grade = grade)
results

# Plot point totals as histogram: 
ggplot(results) +
  geom_histogram(aes(x = pts), binwidth = 1, fill = "steelblue", color = "black") +
  geom_vline(xintercept = thresholds, color = "firebrick", linetype = 2, size = .6) +
  geom_text(aes(label = pts, x = pts, y = 1.02), size = 3, color = "steelblue") +
  geom_text(aes(label = grade, x = pts, y = 1.05), size = 3, color = "firebrick") +
  scale_x_continuous(breaks = seq(0, 50, 5), labels = seq(0, 50, 5)) + 
  labs(title = "Distribution of points and corresponding grades") +
  theme_bw()

# Compute averages and distribution: ---- 
# Descriptives of grades:
all_grades <- readr::parse_number(results$grade)
summary(all_grades)

# As tibble: 
grade_tbl <- tibble(grade = grade, 
                    grade_num = all_grades)
# grade_tbl
names(grade_tbl) <- c("grade", "gnum")
# grade_tbl

# Plot distribution of grades:
library(RColorBrewer)
# display.brewer.all()
col.low.high <- rev(brewer.pal(n = 7, name = "RdYlGn")) # n colors (from green to red)

ggplot(grade_tbl, aes(x = grade, fill = grade)) +
  geom_bar(color = "grey33") +
  scale_fill_manual(values = rev(col.low.high)) + 
  labs(title = "Distribution of grades") +
  theme_bw()
```

[Last update on `r Sys.time()` by [hn](http://neth.de/).]  

<!-- eof. --> 