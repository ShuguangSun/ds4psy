---
title: "Test Questions (ds4psy)"
author: "Hansjörg Neth, SPDS, uni.kn"
date: "2018 05 28"
output:
  rmdformats::html_clean:
    highlight: kate
---

```{r preamble, echo = FALSE, cache = FALSE, message = FALSE, warning = FALSE}
## (a) Housekeeping: -----
rm(list=ls()) # clean all.

## (b) Current file name and path: ----- 
# cur.path <- dirname(rstudioapi::getActiveDocumentContext()$path)
# cur.path
# setwd(cur.path) # set to current directory
setwd("~/Desktop/stuff/Dropbox/_code/R/_teachR/ds4psy/R/_testQuest") # set to current directory
# list.files() # all files + folders in current directory
fileName <- "tq_now.Rmd"

## (c) Packages: ----- 
library(knitr)
library(rmdformats)
library(tidyverse)

## (d) Global options: ----- 
options(max.print="75")
opts_chunk$set(echo = TRUE,
	             cache = TRUE,
               prompt = FALSE,
               tidy = FALSE,
               collapse = TRUE, # set TRUE in answers 
               comment = "#>",
               message = FALSE,
               warning = FALSE,
               fig.width = 9, fig.height = 6)
opts_knit$set(width=75)

## (e) Graphics: ----- 

# Defining colors:
seeblau <- rgb(0, 169, 224, names = "seeblau", maxColorValue = 255) # seeblau.4 (non-transparent)

seeblau.colors <- c(rgb(204, 238, 249, maxColorValue = 255), # seeblau.1
                    rgb(166, 225, 244, maxColorValue = 255), # seeblau.2 
                    rgb(89, 199, 235, maxColorValue = 255),  # seeblau.3
                    rgb(0, 169, 224, maxColorValue = 255),   # seeblau.4 
                    rgb(0, 0, 0, maxColorValue = 255),       #  5. black
                    gray(level = 0, alpha = .6),             #  6. gray 60% transparent
                    gray(level = 0, alpha = .4),             #  7. gray 40% transparent
                    gray(level = 0, alpha = .2),             #  8. gray 20% transparent
                    gray(level = 0, alpha = .1),             #  9. gray 10% transparent
                    rgb(255, 255, 255, maxColorValue = 255)  # 10. white
                    )

unikn.pal = data.frame(                             ## in one df (for the yarrr package): 
  "seeblau1" = rgb(204, 238, 249, maxColorValue = 255), #  1. seeblau1 (non-transparent)
  "seeblau2" = rgb(166, 225, 244, maxColorValue = 255), #  2. seeblau2 (non-transparent)
  "seeblau3" = rgb( 89, 199, 235, maxColorValue = 255), #  3. seeblau3 (non-transparent)
  "seeblau4" = rgb(  0, 169, 224, maxColorValue = 255), #  4. seeblau4 (= seeblau base color)
  "black"    = rgb(  0,   0,   0, maxColorValue = 255), #  5. black
  "seegrau4" = rgb(102, 102, 102, maxColorValue = 255), #  6. grey40 (non-transparent)
  "seegrau3" = rgb(153, 153, 153, maxColorValue = 255), #  7. grey60 (non-transparent)
  "seegrau2" = rgb(204, 204, 204, maxColorValue = 255), #  8. grey80 (non-transparent)
  "seegrau1" = rgb(229, 229, 229, maxColorValue = 255), #  9. grey90 (non-transparent)
  "white"    = rgb(255, 255, 255, maxColorValue = 255), # 10. white
  stringsAsFactors = FALSE)

## (f) Exercise counter: ----- 
nr <- 0
```

# Introduction

## Course Coordinates

<!-- uni.kn logo and link to SPDS: -->  
<!-- ![](./inst/pix/uniKn_logo.png) --> 
<a href="https://www.spds.uni-konstanz.de/">
<img src = "../../inst/pix/uniKn_logo.png" alt = "spds.uni.kn" align = "right" width = "300" style = "width: 300px; float: right; border:20;"/>
<!-- <img src = "./inst/pix/uniKn_logo_s.png" alt = "spds.uni.kn" style = "float: right; border:20;"/> --> 
</a>

* Taught at the [University of Konstanz](https://www.uni-konstanz.de/) by [Hansjörg Neth](http://neth.de/) (<h.neth@uni.kn>,  [SPDS](https://www.spds.uni-konstanz.de/), office D507).
* Spring/summer 2018: Mondays, 13:30--15:00, C511 (from 2018.04.16 to 2018.07.16) 
* Links to [ZeUS](https://zeus.uni-konstanz.de:443/hioserver/pages/startFlow.xhtml?_flowId=showEvent-flow&unitId=5101&termYear=2018&termTypeValueId=1&navigationPosition=hisinoneLehrorganisation,examEventOverviewOwn) and [Ilias](https://ilias.uni-konstanz.de/ilias/goto_ilias_uni_crs_758039.html)

## Test Questions

This file contains practice and test questions suited to test your skills and understanding. It also illustrates the procedure of our **mid-term exam** (on June 4, 2018).

## Preparation and response format

**`r nr`.** Please answer the following questions by creating a single R script that contains all your code and answers and meets the following criteria: 

- Save your script (regularly) as `Lastname_Firstname_midTerm_180528.R`.

- Include a header that contains your name, your student ID, this course, and today's date.

- Load the R packages of the `tidyverse`. 

- Structure your file by clearly marking the current task (e.g., `# Task 1: -----`) and subtask (e.g., `# (a):`).

- Include answers to all questions as comments in your script.

- Send your script by email (as an attachment) to <h.neth@uni.kn> by 15:15 (today). 

```{r, header, echo = TRUE}
## Mid-term exam  | Data science for psychologists (Summer 2018)
## Name: ... | Student ID: ...
## 2018 05 28
## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##

## Preparations: ----- 

library(tidyverse)

## Task 1: ----- 

## (a):
df <- as_tibble(PlantGrowth)
dim(df) 

## Answer: 30 rows x 2 columns.

## (b): 
## ...

## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
## End of file. ----- 
```


# 3: Data visualisation

## Key skills

The chapter introduces visualizations (with `ggplot`), but not yet data transformations (with `dplyr`). Specifically, the chapter illustrates: 

- scatterplots (`geom_point`) and trendlines (`geom_smooth`)
- grouping (via aesthetic mappings like `color`, `shape`, `size`, etc.)
- facetting (`facet_wrap` and `facet_grid`)
- bar charts (`geom_bar`) for given values (`stat = "identity"`), frequencies, and proportions and different positions (e.g., `stack`, `fill` and `dodge`) 
- boxplots (`geom_boxplot`)
- adjusting coordinates (`coord_cartesian`, `coord_flip`, and `coord_polar`)

## Example tasks 

### Using `PlantGrowth` data

**`r nr<-nr+1; nr`.** The `PlanthGrowth` data (contained in R datasets) reports the results from an experiment to compare yields (measured by the dried weight of plants) obtained under a control vs. 2 treatment conditions.

**`r nr`a.** Save the `PlantGrowth` data as a tibbble and inspect its dimensions (1 point).

**`r nr`b.** Use a `dplyr` pipe to compute the number of observations (rows) by group, 
their mean, median, and standard deviations (2).

**`r nr`c.** Use `ggplot` to create a graph that shows the medians and raw values of plant `weight` by `group` (2). 

```{r, plantGrowth, echo = TRUE, eval = TRUE}
# ?PlantGrowth

# (a): 
df <- as_tibble(PlantGrowth)
df # => 30 cases (rows) x 2 variables (columns)

# (b) Compute number of observations by group, their mean, median and standard deviation: 
df %>%
  group_by(group) %>%
  summarise(count = n(),
            mn_weight = mean(weight),
            md_weight = median(weight),
            sd_weight = sd(weight)
            )

# (c) Plot the median and raw values of weight by group: 
ggplot(df, aes(x = group, y = weight, color = group)) +
  # geom_violin() +
  geom_boxplot() +
  geom_point(alpha = 2/3, size = 5, position = "jitter")
```

### Using `sleep` data

**`r nr<-nr+1; nr`.** The `sleep` data (contained in R datasets) shows the effect of 2 sleep-promoting drugs (as an increase in hours of sleep compared to a control group) on 10 patients.

**`r nr`a.** Save the `sleep` data as a tibbble and inspect its dimensions (1 point). 

**`r nr`b.** Use a `dplyr` pipe to compute the number of observations (rows) by group, 
their mean, median, and standard deviations (2).

**`r nr`c.** Use `ggplot` to create a graph that shows the medians and raw values of `extra` sleep time by `group` (2). 

**`r nr`d.** Reformat the `sleep` data so that the 2 groups appear in 2 lines (rows) and IDs as 10 columns (1).

```{r, sleep, echo = TRUE}
# ?sleep

# (a)
df <- as_tibble(sleep)
df # => 20 x 3

# (b) Compute the number of observations and descriptives of extra time by group:
df %>% 
  group_by(group) %>%
  summarize(n = n(),
            md = median(extra),
            mn = mean(extra),
            sd = sd(extra))

# (c) Visualize the raw values and averages by group:
ggplot(df, aes(x = group, y = extra, color = group)) +
  geom_boxplot() +
  # geom_violin() +
  geom_point(aes(shape = group), size = 3, position = "jitter")

# (d) Reformat data so that the 2 groups appear in 2 lines, and IDs as 10 columns:
df %>%
  spread(key = ID, value = extra)
```


### Using `ChickWeight` data

```{r, chickWeight, echo = TRUE}
# ?ChickWeight

df <- as_tibble(ChickWeight)
df

# Scatter & line plot showing weight development of each chick over Time:
ggplot(df, aes(x = Time, y = weight, group = Diet)) +
  facet_wrap(~Diet) + 
  geom_point(alpha = 1/2) +
  geom_line(aes(group = Chick)) +
  geom_smooth(aes(color = Diet))

# Plot the weight of each individual chick 
# and the Median weight per diet at the end (Time = 21).
# Hint: Filter data for the maximum time and combine a scatterplot with a boxplot.
df %>%
  filter(Time == 21) %>%
  ggplot(., aes(x = Diet, y = weight, fill = Diet)) +
    geom_boxplot() +
    geom_point(size = 4) +
    coord_flip()

# Bar plot showing the number (count) of chicks per diet over time: 
ggplot(df, aes(x = Time, fill = Diet)) +
  geom_bar(position = "dodge")

# Bonus: Re-create the counts of chicks per diet over time numerically 
# (by using `dplyr` and `tidyr`). 

# How many chicks per diet over time?
df %>%
  group_by(Diet, Time) %>%
  count() %>%
  spread(key = Time, value = n)
```

### Using `mtcars` data

```{r, mtcars, echo = TRUE}
## Data to use:
?mtcars
# mtcars

## (0) Convert into a tibble: 
df <- as_tibble(rownames_to_column(mtcars, var = "model"))
df$cyl <- factor(df$cyl)
df$am <- factor(df$am)
df

## (1) Distribution of mpg: ---- 
range(df$mpg)

ggplot(df, aes(x = mpg)) +
  geom_histogram(binwidth = 5) 

## (2) Group means and boxplot: Mean mpg by cylinder: ----  

df %>%
  group_by(cyl) %>%
  summarise(n = n(),
            md_mpg = median(mpg),
            mn_mpg = mean(mpg)
            )

ggplot(df, aes(x = cyl, y = mpg, color = cyl)) +
  geom_boxplot() +
  # geom_violin() + 
  geom_jitter()

## (3) Scatterplot: ---- 

## Show value of `disp` (on y-axis) by `hp` (on x-axis), grouped by `am`: 
ggplot(df, aes(x = hp, y = disp, fill = am)) +
  geom_point(shape = 21, size = 2.5) +
  # geom_smooth() +
  geom_text(aes(label = model), size = 2.5, vjust = 0, hjust = 0, nudge_x = 5) +
  theme_bw()

## Alternative (using facets):
ggplot(df, aes(x = hp, y = disp)) +
  facet_wrap(~am) + 
  geom_point(size = 2.5) +
  # geom_smooth() +
  geom_text(aes(label = model), size = 2.5, vjust = 0, hjust = 0, nudge_x = 5) +
  theme_bw()

## Conclusions: ---- 
# - There is a positive correlation between horsepower and displacement 
#   (for both types of transmission). 
# - outliers: Ford Pantera L and Maserati 
#             have more hp and disp than other cars with manual transmission.
```

#### Tasks involved

- Plot distribution (histogram) 
- Descriptive group measures (count, mean, SD) 
- Plot raw data and group means (boxplot) 
- Plot scatterplot of 2 continuous variables  
- Interpret and draw conclusions 

### Using `tidyr::table1` data 

**`r nr<-nr+1; nr`.** The `tidyr::table1` shows the number of TB cases for 3 countries and 2 years. 

**`r nr`a.** Plot a bar chart that shows the number of cases per `country` (on the y-axis) as a function of the `year` (on the x-axis) (2).

**`r nr`b.** Format the bars (showing cases per `country`) in different colors (1). 

**`r nr`c.** Provide a suitable plot title and a caption noting the data source (1). 

**`r nr`d.** Label each bar with the number of cases (1). 

```{r, barchart_with_labels, echo = FALSE, eval = TRUE}
# ?geom_bar
?tidyr::table1

ggplot(tidyr::table1, aes(x = year, y = cases, fill = country)) + 
  geom_bar(stat = "identity", position = "dodge", color = "black") + 
  geom_text(aes(label = cases), position = position_dodge(width = 0.9), vjust = -0.5) +
  scale_x_continuous(name = "Year", breaks = 1999:2000) + 
  labs(title = "Cases per country and year", y = "Cases", caption = "[Data from tidyr::table1.]") +
  theme_light()
```

### Own data: German election results

Create tibble and then visualize election results, which are given as a table:

| Party: | Share 2017:       | Share 2013: | 
|:------- |--------:         |--------:|
| CDU/CSU | `r (26.8+6.2)`%  | `r (34.1 + 7.4)`% |
| SPD     | `r (20.5)`%      | `r (25.7)`% |
| others  |      ?           |        ?    |


<!-- From https://www.bundeswahlleiter.de/info/presse/mitteilungen/bundestagswahl-2017/34_17_endgueltiges_ergebnis.html 

CDU 	Christlich Demokratische Union Deutschlands 	26,8 % 	(2013: 34,1 %)
SPD 	Sozialdemokratische Partei Deutschlands 	    20,5 % 	(2013: 25,7 %)
AfD 	Alternative für Deutschland 	                12,6 % 	(2013:  4,7 %)
FDP 	Freie Demokratische Partei 	                  10,7 % 	(2013:  4,8 %)
DIE LINKE 	DIE LINKE 	                             9,2 % 	(2013:  8,6 %)
GRÜNE 	    BÜNDNIS 90/GRÜNE 	                       8,9 % 	(2013:  8,4 %)
CSU 	Christlich-Soziale Union in Bayern e.V 	       6,2 % 	(2013:  7,4 %)
Sonstige 	  	                                       5,0 % 	(2013:  6,2 %)

--> 

```{r, election_results}
## (a) Create a data frame or tibble:
df <- data.frame(
    party = c("CDU/CSU", "SPD", "others"),
    share = c((.268 + .062), .205, (1 - (.268 + .062) - .205))
  )
df$party <- factor(df$party, levels = c("CDU/CSU", "SPD", "others"))
head(df)
  
## (b) Create a stacked bar chart:
bp <- ggplot(data = df, mapping = aes(x = "", y = share, fill = party)) +
  geom_bar(stat = "identity") + 
  scale_fill_manual(values = c("black", "red3", "gold")) + 
  theme_bw()
bp

## (c) Create a pie chart: 
pie <- bp + coord_polar("y", start = 0)
pie
```

- Create a data frame or tibble
- Plot bar chart (with `stat = "identity"`)
- Create pie chart (with `coord_polar`) 



# 5: Data transformation

```{r, setup_5, echo = TRUE, eval = TRUE}
library(tidyverse)    # dplyr
library(nycflights13) # data
```

## Key skills

Transform data with essential `dplyr` commands:

- `filter` and `arrange` cases (rows)
- `select` and re-arrange variables (columns)
- add and compute new variables with `mutate` and `transmute`
- compute counts and descriptives of aggregates (by `group_by`, `summarise`, and functions)
- compute new group-level variables (by grouped mutates) 

## Example tasks 

### Using `dplyr::starwars` dataset

Exploring the `dplyr::starwars` universe: 

Save the tibble `dplyr::starwars` as `df` and then answer the following questions by filtering, grouping, counting, summarizing, and sorting (i.e., using basic `dplyr` commands):

```{r, starwars_transformations}
## Data: 
df <- dplyr::starwars
# df

## (1)  and determine basic data properties: ---- 

# (a) How many individuals (rows) and variables (columns) are there?
dim(df)  # => 87 x 13

# (b) How many missing data points?
sum(is.na(df))  # 101

## (2) Gender issues: ----- 

# (a) How many humans are there of each gender?
df %>% 
  filter(species == "Human") %>%
  group_by(gender) %>%
  count()

# (b) How many and which individuals are neither male nor female?
df %>% 
  filter(gender != "male", gender != "female")


## (3) Homeworld issues: ----- 

# (a) From which homeworld do the most indidividuals (rows) come from?
df %>%
  group_by(homeworld) %>%
  count() %>%
  arrange(desc(n))

# (b) List all individuals with orange eyes that come from this homeworld.
df %>% 
  filter(homeworld == "Naboo", eye_color == "orange")

# Note: 
df %>% filter(eye_color == "orange") # => 8 individuals

# (c) What is the mass and homeworld of the smallest droid?
df %>% 
  filter(species == "Droid") %>%
  arrange(height)

# (d) Which individuals come from an unknown (missing) homeworld 
#     but have a known birth_year or mass? 
df %>% 
  filter(is.na(homeworld), !is.na(mass) | !is.na(birth_year))


## (4) Group summaries: ----- 

# (a) How many individuals come from the 3 most frequent (known) species?
df %>%
  group_by(species) %>%
  count %>%
  arrange(desc(n))

# (b) Compute the mean height and standard deviation of all human individuals by gender.
df %>%
  filter(species == "Human") %>%
  group_by(gender) %>%
  summarise(n = n(),
            not_NA_h = sum(!is.na(height)),
            mn_height = mean(height, na.rm = TRUE),
            sd_height = sd(height, na.rm = TRUE))

# (c) Compute the average height and mass by species and save the result as `h_m`:
h_m <- df %>%
  group_by(species) %>%
  summarise(n = n(),
            # not_NA_h = sum(!is.na(height)),
            mn_height = mean(height),
            # not_NA_m = sum(!is.na(mass)),
            md_mass = median(mass)
            )
# h_m

# (d) Use `h_m` to list the 3 species with the smallest individuals (in terms of mean height)?
h_m %>% arrange(mn_height) %>% slice(1:3)

# (e) Use `h_m` to list the 3 species with the heaviest individuals (in terms of median mass)?
h_m %>% arrange(desc(md_mass)) %>%  slice(1:3)
```

### Using `weather` dataset

Use the data set `nycflights13::weather` for questions that require 
`filter`, `arrange`, `select`, `group_by`, `summarise` (count, NAs, means, medians), etc.

```{r, weather_transformations}
library(nycflights13)
nycflights13::weather
# ?weather

## How many observations (rows) and variables (columns) does the data set contain overall?
dim(weather)

## How many missing values does the `weather` data contain?
sum(is.na(weather))  # 
mean(is.na(weather)) # percentage

## What is the range of values of the `year` variable?
range(weather$year)

## How many observations (rows) does the data contain for each of the 3 airports (`origin`)?
weather %>%
  group_by(origin) %>%
  count()

## (On the original data set): 
## Compute a variable `temp_dc` that provides the temperature (in degrees Celsius) 
## that corresponds to `temp` (in degrees Fahrenheit).
## Fahrenheit (degrees F) to Celsius (degrees C) conversion:
## C = (F - 32) x 5/9.

## Add your new `temp_dc` variable to a new dataset `weather_2` and 
## re-arrange its columns so that your `temp_dc` variable appears next to `temp`.

weather_2 <- weather %>%
  mutate(temp_dc = (temp - 32) * 5/9) %>%
  select(origin:temp, temp_dc, everything())
weather_2

## Only considering "JFK" airport: 
## What are the 3 (different) dates with the (a) coldest and (b) hottest temperatures there?
## Report the 3 dates and their extreme temperatures (in degrees Celsius) for (a) and (b). 
JFK_temp <- weather_2 %>%
  filter(origin == "JFK") %>%
  arrange(temp_dc)

JFK_temp # => coldest days
JFK_temp %>% arrange(desc(temp)) # => hottest days


## Aggregation examples: -----

## (1) Average temperature per month: 
##     (used in class): 

weather %>%
  # group_by(origin, month) %>%
  group_by(month) %>%
  summarise(n = n(),
            n_not_NA = sum(!is.na(temp)), 
            mn_temp = mean(temp, na.rm = TRUE)) %>%
  ggplot(aes(x = month, y = mn_temp)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:12) +
  theme_bw()

# (2) Average precipitation (by origin and month):

weather %>%
  group_by(origin, month) %>%
  summarise(n = n(),
            n_not_NA = sum(!is.na(precip)), 
            mn_precip = mean(precip, na.rm = TRUE)) %>%
  ggplot(aes(x = month, y = mn_precip, color = origin)) +
  geom_point() +
  geom_line() +
  # geom_bar(aes(fill = origin), stat = "identity", position = "dodge") +
  scale_x_continuous(breaks = 1:12) +
  theme_bw()


## Computation and visualization to answer a question: ----

## For each of the 3 airports: 
## When excluding extreme cases of precipitation (values of `precip` greater than 0.30): 
## Does it rain more during winter (Oct to Mar) or during summer (Apr to Sep) months?

## Inspect data:
weather # month is given numerically!

# ggplot(weather, aes(x = precip)) +
#  geom_histogram(binwidth = 0.01, fill = seeblau)

## (a) Preparation: Filter out extreme values and add a summer variable: 
weather_season <- weather %>%
  filter(precip < .30) %>%
  mutate(summer = (month > 3 & month < 10)#,
         # winter = (month < 4 | month > 9)
         )

## (b) Computation: Sum of precipitation by origin and summer season:
weather_season %>%
  group_by(origin, summer) %>%
  summarise(n = n(),
            # n_not_NA = sum(!is.na(precip)), 
            # mn_precip = mean(precip, na.rm = TRUE),
            sum_precip = sum(precip, na.rm = TRUE))

## (c) Visualization: Sum of precipitation as a bar chart:
ggplot(weather_season, aes(x = summer, fill = summer)) +
  facet_wrap(~origin) + 
  geom_bar(aes(weight = precip), na.rm = TRUE) +
  scale_fill_manual(values = c("steelblue3", "firebrick"))
```

### Own data: Identifying outliers

#### Definition 

Let's define an _outlier_ as someone deviating by more than 2 SD (in some metric) from the mean of a reference group. Depending on the reference group, outliers can be computed in defined in 2 ways:  

1. relative to _overall_ mean and SD;  

2. relative to _group_ mean and SD.  

Creating a suitable data set: 

```{r, outlier_create_data}
## Generate data: 
set.seed(123)
n <- 1000
id <- paste0("p.", 1:n) # paste0(sample(LETTERS, 1), sample(LETTERS, 1))
sex <- sample(x = c(0, 1), size = n, replace = TRUE)
height <- rep(NA, n)
noise <- round(rnorm(n, mean = 0, sd = 11), 0)
height[sex == 0] <- 169 + noise[sex == 0]
height[sex == 1] <- 181 + noise[sex == 1]

data <- as_tibble(data_frame(id, factor(sex), height))
names(data) <- c("id", "sex", "height")
# data
mean(data$height) # => 175.051
```

#### Tasks

A. Create 2 variables for both types of outliers.

B. Identify people who are outliers relative to _both_ the entire poulation _and_ to their own sex.

C. Identify people (men and women) who are _not_ outliers relative to the entire population, but _are_ outliers relative to their own sex. (As men are taller than women on average, these are tall women and small men.)

D. Visualize the overall distribution of `height`, its distribution by `sex`, 
and the raw data values for both types of outliers (by `sex`).

#### Solution 

To identify both groups, we first need to compute 2 outlier variables: One for the entire population and one for each subgroup (based on people's `sex`).
 
```{r, outlier_solution}
crit <- 2 # criterion for outliers

# (A)
data_out <- data %>%
  mutate(mn_height = mean(height),
         sd_height = sd(height),
         out_height = abs(height - mn_height) > (crit * sd_height)) %>%
  group_by(sex) %>%
  mutate(mn_sex_height = mean(height),
         sd_sex_height = sd(height),
         out_sex_height = abs(height - mn_sex_height) > (crit * sd_sex_height))
data_out

# (B) outliers relative to entire population AND to their own group (sex):
out_1 <- data_out %>%
  filter(out_height & out_sex_height)
out_1

# (C) outliers relative to own sex, but NOT relative to entire population:
out_2 <- data_out %>%
  filter(!out_height & out_sex_height)
out_2

# (D) Visualization of the data: 
# (a) All data: 
p <- ggplot(data) +
  geom_density(aes(x = height), fill = "gold", alpha = 2/3) +
  geom_density(aes(x = height, fill = factor(sex)), alpha = 1/4) +
  theme_bw()
p

p <- ggplot(data) +
  facet_wrap(~sex) + 
  geom_histogram(aes(x = height, fill = factor(sex)), binwidth = 5, alpha = 2/4) +
  # geom_histogram(aes(x = height), binwidth = 10, fill = "forestgreen", alpha = 2/3) +
  # geom_density(aes(x = height, fill = sex)) + 
  theme_bw()
# p

## (b) 2 types of outliers:
ggplot(out_1, aes(x = sex, y = height, color = sex)) +
  geom_violin() + 
  geom_jitter() + 
  theme_bw()

ggplot(out_2, aes(x = sex, y = height, color = sex)) +
  geom_violin() + 
  geom_jitter() +
  theme_bw()
```

### Using `flight` dataset to compute duration

Using the `flights` dataset: 
- Compute a variable `true_duration` as the duration of each flight (in minutes) from its `dep_time` and `arr_time`. 
- How does it relate to the `air_time` variable in the data set? (Plot the relationship between both variables.)

```{r, flights_duration, echo = TRUE}
compute_duration <- function(dep_min, arr_min) {

  dur <- NA # initialize
  
  # Distinguish between 2 cases:
  if (dep_min < arr_min) {  # dep before arr (i.e., same day): 
    dur <- arr_min - dep_min
  } else { # dep later than arr (i.e., different days): 
    dur <- (arr_min + 24 * 60) - dep_min 
  }
  
  return(dur)
  
}

# Check for vectors: 
dep <- seq(0, 24*60, by = +15)
arr <- seq(24*60, 0, by = -15)

# compute_duration(dep, arr)
# ???: How to apply a function to each pair of values of 2 vectors/columns?

d <- flights %>% 
  filter(origin == "JFK") %>%  # to reduce size of dataset
  select(dep_time, arr_time, air_time) %>%
  mutate(dep_time_min = ((dep_time %/% 100) * 60) + (dep_time %% 100),
         arr_time_min = ((arr_time %/% 100) * 60) + (arr_time %% 100),
         # true_duration = compute_duration(dep_time_min, arr_time_min),
         true_duration = arr_time_min - dep_time_min) %>%
  filter(air_time > 0, true_duration > 0)

p <- ggplot(d, (aes(x = air_time, y = true_duration))) +
  geom_point(alpha = 1/4) +
  geom_abline(intercept = 0, slope = 1, linetype = 2, size = 1, color = "red3") +
  theme_bw()
```

#### Notes

- The `dep_time` and `arr_time` are specified in terms of hour and minutes. As an hour contains 60 minutes (rather than 100), we first use modular arithmetic to transform both variables into a metric of minutes (see variables `dep_time_min` and `arr_time_min`).

- For flights departing and arriving on the same day, we can simply subtract `dep_time_min` from `arr_time_min` to obtain `true_duration`. However, if a flight departs before and arrives after midnight (i.e., arrives on the next day), this measure would yield a negative result. To correct for this, we need to add 24 hours (24 times 60 minutes) to `arr_time` whenever `arr_time` is before (or smaller than) `dep_time`. [This assumes that there are no flights exceeding 24 hours.]

- Seems too difficult at this stage, as it requires _conditional execution_ (for flights departing and arriving on the same vs. different days) and/or _functions_. 

In chapter 16 (Dates and times: http://r4ds.had.co.nz/dates-and-times.html), this problem is solved by introducing a Boolean variable for `overnight` flights and re-computing `air_time` by subtracting date-time objects (as intervals). 


# 7: Exploratory Data Analysis 

## Key skills

Transform and visualize datasets to: 

- detect and deal with missing values
- view distributions of variables and outliers  
- plot and interpret relationships between (categorical/continuous) variables 

## Example tasks 

### Using `iris` data

```{r, iris_EDA}
?iris

## Turn into tibble: ----- 
df <- as_tibble(iris)
df

## Compute group counts and means: ----- 
df %>%
  group_by(Species) %>%
  summarise(n = n(),
            mn_sep.len = mean(Sepal.Length),
            mn_sep.wid = mean(Sepal.Width),
            mn_pet.len = mean(Petal.Length),
            mn_pet.wid = mean(Petal.Width)
            )

## Graphical exploration: ----- 

# (a) Means by species:
ggplot(df, aes(x = Species, y = Sepal.Width, fill = Species)) +
  # geom_violin() +
  geom_boxplot() +
  geom_point(position = "jitter")

ggplot(df, aes(x = Species, y = Petal.Length, fill = Species)) +
  # geom_violin() +
  geom_boxplot() +
  geom_point(position = "jitter")

# (b) Relationship between 2 variables: 
ggplot(df, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
  facet_wrap(~Species) +
  geom_point(size = 3, alpha = 1/2, position = "jitter") +
  # geom_smooth() +
  # geom_density2d() +
  coord_fixed()

ggplot(df, aes(x = Petal.Length, y = Petal.Width, color = Species)) +
  facet_wrap(~Species) +
  geom_point(size = 3, alpha = 1/2, position = "jitter")

ggplot(df, aes(x = Sepal.Width, y = Petal.Width, color = Species)) +
  facet_wrap(~Species) +
  geom_point(size = 3, alpha = 1/2, position = "jitter") +
  # geom_density2d() +
  coord_fixed()

## Turn iris df into long format using tidyr::gather ----- 
## (see Chapter 12: Tidy Data below)
```


# 10: Tibbles

## Key skills

Turn data into tibbles: 

- convert data frames into tibbles (by `as_tibble`) 
- create tibbles from tabular data (by `tibble` and `tribble`)



# 12: Tidy Data

## Key skills

Wrangle data to: 

- identify and create tidy datasets
- `gather` (wider) datasets into longer ones
- `spread` (longer) datasets into wider ones
- `separate` and `unite` variables (columns)

## Example tasks 

### Using `iris` dataset

```{r, iris_tidyr}
# ?iris

## Turn into tibble: ----- 
df <- as_tibble(iris)
df

## Compute group counts and means: ----- 
cm1 <- df %>%
  group_by(Species) %>%
  summarise(n = n(),
            mn_sep.len = mean(Sepal.Length),
            mn_sep.wid = mean(Sepal.Width),
            mn_pet.len = mean(Petal.Length),
            mn_pet.wid = mean(Petal.Width)
            )
cm1
## Check: Sum of all means  
sum(cm1$mn_sep.len) + sum(cm1$mn_sep.wid) + sum(cm1$mn_pet.len) + sum(cm1$mn_pet.wid)  # => 41.574


## Turn df into long format using tidyr::gather ----- 
df_long <- df %>%
  gather(Sepal.Length:Petal.Width, key = "type", value = "val") %>%
  separate("type", into = c("part", "metric"), sep = "\\.")

df_long
dim(df_long)

## Recompute group counts and means: ----- 
cm2 <- df_long %>%
  group_by(Species, part, metric) %>%
  summarise(n = n(),
            mn_val = mean(val)
            )
cm2

## Check: Sum of all means  
sum(cm2$mn_val) # => 41.574


## Bonus task: Turn df_long back into original wide format using tidyr::spread -----
df_long

df_long <- rownames_to_column(df_long, var = "id") # add id column
df_long$id <- parse_integer(df_long$id)            # make integer
df_long

df_long %>%
  unite(type, part, metric, sep = ".") %>%  # unite part and metric into "type" column
  spread(key = type, value = val) %>%      # spread "type" variable into multiple columns
  arrange(id)

# ???: Still contains 600 rows (and 3 out of 4 empty columns).
# +++ here now +++

```

### Using own stock (`st`) dataset

**`r nr<-nr+1; nr`.** The following table shows the start and end price of 3 stocks on 3 days (d1, d2, d3):

| stock | d1_start | d1_end | d2_start | d2_end | d3_start | d3_end |  
|-------|----------|--------|----------|--------|----------|--------|
| "Amada"|   2.5  |   3.6   |  3.5    |    4.2  |   4.4   |   2.8  |            
| "Betix"|   3.3  |   2.9   |  3.0    |    2.1  |   2.3   |   2.5  |  
| "Cevis"|   4.2  |   4.8   |  4.6    |    3.7  |   3.8   |   3.1  |

**`r nr`a.** Create a tibble `st` that contains this data in this (wide) format (1). 

**`r nr`b.** Transform `st` into a longer table `st_long` that contains 18 rows and only 1 numeric variable for all stock prices (1). 
Adjust it so that the `day` and `time` appear as 2 separate columns (1). 

**`r nr`c.** Create a graph that shows the 3 stocks' `end` prices (on the y-axis) over the 3 days (on the x-axis) (1).

**`r nr`d.** Spread  `st_long` into a wider table that contains `start` and `end` prices as 2 distinct variables (columns) for each stock and day (1).

```{r, stock_data, echo = TRUE}
# library(tidyverse)

## (a) Enter stock data (in wide format) as a tibble:

st <- tribble(
  ~stock, ~d1_start, ~d1_end, ~d2_start, ~d2_end, ~d3_start, ~d3_end,  
  #-----|----------|--------|----------|--------|----------|--------|
  "Amada",   2.5,     3.6,    3.5,       4.2,      4.4,       2.8,            
  "Betix",   3.3,     2.9,    3.0,       2.1,      2.3,       2.5,  
  "Cevis",   4.2,     4.8,    4.6,       3.7,      3.8,       3.1     
)
# st

## Note data structure: 
## 2 nested factors: day (1 to 3), type (start or end).

## (b) Change from wide to long format 
##     that contains the day (d1, d2, d3) and type (start vs. end) as separate columns:
st_long <- st %>%
  gather(d1_start:d3_end, key = "key", value = "val") %>%
  separate(key, into = c("day", "time")) %>%
  arrange(stock, day, time) # optional: arrange rows
st_long

## (c) Plot the end values (on the y-axis) of the 3 stocks over 3 days (x-axis):
st_long %>% 
  filter(time == "end") %>%
  ggplot(aes(x = day, y = val, color = stock, shape = stock)) +
  geom_point(size = 3) + 
  geom_line(aes(group = stock))

## (d) Change st_long into a wider format that lists start and end as 2 distinct variables (columns):
st_long %>%
  spread(key = time, value = val) %>%
  mutate(day_nr = parse_integer(str_sub(day, 2, 2))) # optional: get day_nr as integer variable

## (e) Note: Assume that stock data contains duplicate rows:
st2 <- rbind(st, st)
st2

## Gathering from wide to long format works as before: 
st_long2 <- st2 %>%
  gather(d1_start:d3_end, key = "key", value = "val") %>%
  separate(key, into = c("day", "time")) %>%
  arrange(stock, day, time) # optional: arrange rows
st_long2

## However, spreading from long to wider format yields error of "duplicate identifiers": 

# st_long2 %>%
#  spread(key = time, value = val) 

## would yield ERROR!

## Possible fix:
## (e1) Add an id variable that distinguishes between duplicate cases: 
st_long3 <- st_long2 %>%
  mutate(id = rep(1:2, nrow(st_long2)/2)) %>%  # adding a vector
  select(stock, id, everything())               # optional: re-arrange variables (columns)
# st_long3

## (e2) Now spreading from long to wider format succeeds: 
st_long3 %>%
  spread(key = time, value = val)
```




# All chapters

Create a (psychological) dataset that allows illustrating contents from all chapters. 

### Create people data

```{r, create_people_data, include = TRUE}
n <- 1000     # [n]umber of participants
set.seed(42)  # for replicability

## Demographics: -----

## Generate random initials: ----
r_initials <- function(n) {

  stopifnot(is.numeric(n), n > 0) # check conditions
  
  initials <- rep("N.N", n) # initialize output vector
  
  for (i in 1:n) {
    initials[i] <- paste0(paste(sample(LETTERS, 1), sample(LETTERS, 1), sep = "."), ".")
  }
  return(initials)
}

## Check:
# r_initials(100)
# length(LETTERS)^2 # => 676 possible sequences
# length(unique(r_initials(10000))) # => 676 
initials <- r_initials(n)

## Sex/gender: 
sex <- sample(x = c(0, 1), size = n, prob = c(.54, .46), replace = TRUE)
sex <- factor(sex, labels = c("female", "male"))

## Generate a (pseudo) random age distribution: ---- 
r_ages <- function(n, min = 16, max = 92) {
  
  stopifnot(is.numeric(n), n > 0) # check conditions

  ages <- rep(NA, n) # initialize output vector
  
  # (a) sample from stepwise distribution: 
  ages <- sample(size = n, 
                 x = c(min:max, 18:85, 20:39, 22:36, 24:33, 26:30, 35:63, 44:61, 65:77), # oversampling some regions
                 replace = TRUE)
  
  # (b) smoothing by adding random noise: 
  ix.not_extreme <- which((ages > (min + 2)) & (ages < (max - 2)))
  ages[ix.not_extreme] <- ages[ix.not_extreme] + sample(size = length(ix.not_extreme), -2:2, replace = TRUE)
  
  return(ages)
}

ages <- r_ages(n)

## Check:
ggplot(as_tibble(ages), aes(x = value)) +
  geom_histogram(binwidth = 1, fill = seeblau) # +
  # geom_density()

## Big sample: 
# ggplot(as_tibble(r_ages(100000)), aes(x = value)) +
#  # geom_density() + 
#  geom_histogram(binwidth = 1, fill = seeblau)


## Convert ages into birthdays: ----
library(lubridate)

r_bday <- function(ages) {
  
  stopifnot(is.numeric(ages), ages > 0) # check conditions

  n <- length(ages)
  bdays <- rep(NA, n) # initialize output 
  
  # Compute bdays as today() - age (in years) - some random day within this year:
  bdays <- today() - years(ages) - days(sample(size = n, 0:365, replace = TRUE)) 
  
  return(bdays)
  
}

bdates <- r_bday(ages)
byears <- year(bdates)
bmonths <- month(bdates, label = FALSE)
bdays <- day(bdates) 
bmdays <- paste0(bmonths, "/", bdays)
bweekdays <- wday(bdates, label = TRUE)

## Check:
t <- tibble(id = initials,
            sex = sex, 
            age = ages,
            bdate = bdates,
            byear = year(bdates),
            bmonth = month(bdates, label = FALSE),
            bday = day(bdates), 
            bmday = paste0(bmonths, "/", bdays), 
            bweekday = wday(bdates, label = TRUE), 
            age_y = year(today())- year(bdates)  # Note deviation from ages 
            # if bday hasn't been reached yet this year
)
# t

# t %>% arrange(bdate)
# t %>% arrange(age)

## Height: ----- 
## From https://en.wikipedia.org/wiki/List_of_average_human_height_worldwide 

##          Average male:             Average female:
## -----------------------------------------------------##
## Germany: 178 cm (5 ft 10 in) 	    165 cm (5 ft 5 in)
## USA:     175.7 cm (5 ft 9 in) 	    161.8 cm (5 ft 3 1⁄2 in)

heights <- rep(NA, n)

noise_female <- round(rnorm(sum(sex == "female"), mean = 0, sd = 8), 0)
noise_male   <- round(rnorm(sum(sex == "male"), mean = 0, sd = 11), 0)

heights[sex == "female"] <- 165 + noise_female
heights[sex == "male"]   <- 178 + noise_male

## Reduce height by age (1cm per decade): 
heights[byears < 2000] <- heights[byears < 2000] -  1
heights[byears < 1990] <- heights[byears < 1990] -  1
heights[byears < 1980] <- heights[byears < 1980] -  1
heights[byears < 1970] <- heights[byears < 1970] -  2
heights[byears < 1960] <- heights[byears < 1960] -  1
heights[byears < 1950] <- heights[byears < 1950] -  2
heights[byears < 1940] <- heights[byears < 1940] -  1
heights[byears < 1930] <- heights[byears < 1930] -  2

## Convert metric (cm) into imperial (feet and inches)...

## Check:
sex_height <- tibble(sex = sex,
                     byear = byears, 
                     height = heights)

## Height by sex:
ggplot(as_tibble(sex_height), aes(x = sex, y = height, color = sex)) +
  geom_violin() +
  geom_jitter(alpha = 1/2)

## Height by age and sex:
ggplot(as_tibble(sex_height), aes(x = byears, y = height)) +
  facet_wrap(~sex) +
  geom_jitter(alpha = 1/3) +
  geom_smooth()


## Blood type: -----
## From https://en.wikipedia.org/wiki/Blood_type_distribution_by_country 

## Types:   O+ 	   A+ 	    B+ 	    AB+ 	  O− 	    A− 	    B− 	    AB−
## --------------------------------------------------------------------- ##
## Germany:35.0% 	 37.0% 	  9.0% 	  4.0% 	  6.0% 	  6.0% 	  2.0% 	  1.0%
## USA:    37.4% 	 35.7% 	  8.5% 	  3.4% 	  6.6% 	  6.3% 	  1.5% 	  0.6%
## World:  38.67%  27.42%  22.02% 	5.88% 	2.55% 	1.99% 	1.11% 	0.36%

blood_types <- c("O+", "A+", "B+", "AB+", "O−", "A−", "B−", "AB−")
# blood_probs <- c(.35, .37, .09, .04, 	.06, .06,  .02,	.01)  # Germany
blood_probs <- c(.374, .357, .085, .034, 	.066, .063,  .015,	.006)  # USA
# sum(blood_probs) # should be 1.00

btypes <- sample(size = n, blood_types, prob = blood_probs, replace = TRUE)
# table(btypes)

## Other possible IVs: ----- 
## - education (categorical)
## - weight (compute via height and BMI distribution)

## Combine IVs: ----- 
IVs <- tibble(name = initials,
              gender = sex, 
              # bdate = bdates,
              byear = byears, 
              bmonth = bmonths,
              bday = bdays,
              bweekday = bweekdays,
              height = heights, 
              blood_type = btypes)
IVs


## DVs: -----

## - disposable income (numeric)
## - numeracy (categorical)
## - health status (numeric, e.g., 1:10 scale)
## - mood (1:5, on 3 days: Mon, Wed, Fri, and 2 times: 10:00 vs. 18:00)

## To compute (from IVs):
## - Age (from byear, but adjusting by bday)
## - Birth season (spring, summer, autumn, winter)
## - Zodiac sign (from birthday)
```


Adding a random amount (number or proportion) of NA values to a vector:

```{r add_random_NA_values}

## Function to replace a random amount of vector elements by NA values:  
add_NAs <- function(vec, amount){
  
  stopifnot((is.vector(vec)) & (amount >= 0) & (amount <= length(vec)))

  out <- vec
  n <- length(vec)
  
  amount2 <- ifelse(amount < 1, round(n * amount, 0), amount) # turn amount prop into n
  
  out[sample(x = 1:n, size = amount2, replace = FALSE)] <- NA
  
  return(out)

}

## Check:
add_NAs(1:10, 0)
add_NAs(1:10, 3)
add_NAs(1:10, .5)
add_NAs(letters[1:10], 3)

## Generalization: Replace a random amount of vector elements by what: 
add_whats <- function(vec, amount, what = NA){
  
  stopifnot((is.vector(vec)) & (amount >= 0) & (amount <= length(vec)))

  out <- vec
  n <- length(vec)
  
  amount2 <- ifelse(amount < 1, round(n * amount, 0), amount) # turn amount prop into n
  
  out[sample(x = 1:n, size = amount2, replace = FALSE)] <- what
  
  return(out)

}

## Check:
add_whats(1:10, 3) # default: what = NA
add_whats(1:10, 3, what = 99)
add_whats(1:10, .5, what = "ABC")

```

+++ here now +++

### Create experimental data

```{r, create_exp_data, include = TRUE}
n <- 10       # [n]umber of participants
set.seed(88)  # for replicability

IVs <- data.frame("name" = c("Ann", "Bea", "Cat", "Deb", "Eva", "Fred", "Gary", "Hans", "Ian", "John"),
                  "gender" = c(rep("f", 5), rep("m", 5)), 
                  "age" = sample(18:65, n, replace = TRUE)
                   )
IVs

## (a) within-subjects conditions (with multiple tasks per person):
DVs <- data.frame("task.1" = rep(c("red", "blue"), 5),
                   # "pos.1" = rep(1, n),
                   "time.1" = sample(10:99, n), 
                   "task.2" = rep(c("blue", "red"), 5),
                   # "pos.2" = rep(2, n),
                   "time.2" = sample(10:99, n)
                   )
DVs


## (b) between-subjects conditions (with separate variables):

# DVs2 <- data.frame("cond" = c(rep("A", n/2), rep("B", n/2)),
#                    "A.num1" = c(sample(1:7, n/2), rep(NA, n/2)), 
#                    "B.num1" = c(rep(NA, n/2), sample(3:9, n/2)),
#                    "A.chr1" = c(sample(c("ABBA", "Beatles"), n/2, replace = TRUE), rep(NA, n/2)), 
#                    "B.chr1" = c(rep(NA, n/2), sample(c("ABBA", "Pink Floyd"), n/2, replace = TRUE))
#                    )

DVs2 <- data.frame("cond" = rep(c("A", "B"), n/2))

DVs2$A.num1 <- NA
DVs2$A.num1[DVs2$cond == "A"] <- c(sample(1:6, n/2, replace = TRUE))
DVs2$B.num1 <- NA
DVs2$B.num1[DVs2$cond == "B"] <- c(sample(4:9, n/2, replace = TRUE))

DVs2$A.chr1 <- NA
DVs2$A.chr1[DVs2$cond == "A"] <- c(sample(c("Abba", "Beatles"), n/2, replace = TRUE))
DVs2$B.chr1 <- NA
DVs2$B.chr1[DVs2$cond == "B"] <- c(sample(c("Beatles", "Zappa"), n/2, replace = TRUE))
DVs2

# Note that DVs encodes order (or chronological trial position) 
# implicitly (as 1st vs. 2nd entry) for every case.

## Combine IVs and DVs: 
exp <- cbind(IVs, DVs)
exp2 <- cbind(IVs, DVs2)

# exp
# exp2

dim(exp)
dim(exp2)
```

Basic manipulations of `exp` data (in base R):

```{r, manipulate_exp_data, include = TRUE}
exp.t <- exp # temporal copy

# 1. Adding 2 new variables/columns to a df by assigning/using it: 
exp.t$id <- 1:nrow(exp.t)
exp.t$bnt <- sample(1:4, n, replace = TRUE)
# exp.t

# 2. Swap some columns (e.g., putting id to front): 
id.col  <- which(names(exp.t) == "id")  # determine id column
bnt.col <- which(names(exp.t) == "bnt") # determine bnt column
exp.t <- exp.t[ , c(id.col, 1:(id.col - 1), bnt.col)]
exp.t

# 3. Sorting cases: 
exp.t[order(exp.t$task.1, exp.t$bnt),] # sort cases by task.1 and bnt values

# 4. Reversing cases and variables: 
#    Reversing the (arbitrary) order of all cases and all variables in df:
exp.t[rev(1:nrow(exp.t)), rev(1:ncol(exp.t))]
```

Same steps in the `tidyverse`:

```{r, manipulate_exp_data_tidyverse, include = TRUE}
exp.t2 <- exp # temporal copy

# 1. Adding 2 new variables/columns to a df by assigning/using it: 
exp.t2 <- exp.t2 %>%
  mutate(id = 1:nrow(exp.t2),
         bnt = sample(1:4, n, replace = TRUE))
# exp.t2

# 2. Swap some columns (e.g., putting id to front): 
exp.t2 <- exp.t2 %>%
  select(id, everything())
# exp.t2

# 3. Sorting cases:
exp.t2 <- exp.t2 %>%
  arrange(task.1, bnt)
# exp.t2

# 4. Reversing cases and variables: 
#    Reversing the (arbitrary) order of all cases and all variables in df:
exp.t2 %>%
  mutate(row = 1:nrow(exp.t2)) %>%  # add helper column 
  arrange(desc(row)) %>%
  select(-row) %>%                  # remove helper column again 
  select(rev(names(exp.t2)))
```

[This file last updated on `r Sys.time()` by [hn](http://neth.de/).]

<!-- eof. --> 