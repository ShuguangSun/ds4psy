---
title: "Exploring data, with solutions (EDA, ds4psy)"
author: "Hansjörg Neth, SPDS, uni.kn"
date: "2018 11 21"
output:
   rmdformats::html_clean: # html_clean html_docco readthedown material #
     code_folding: show # hide
     toc_float: true
     toc_depth: 3
     highlight: default # textmate default kate haddock monochrome #
     lightbox: true # true by default
     fig_width: 7 # in inches
editor_options: 
  chunk_output_type: console # inline
---

<!-- Example of essential commands | ds4psy: Winter 2018 -->

```{r preamble, echo = FALSE, eval = TRUE, cache = FALSE, message = FALSE, warning = FALSE}
## (a) Housekeeping: -----
rm(list=ls()) # clean all.

## (b) Current file name and path: ----- 
# cur.path <- dirname(rstudioapi::getActiveDocumentContext()$path)
# cur.path
# setwd(cur.path) # set to current directory
setwd("~/Desktop/stuff/Dropbox/_code/R/_teachR/ds4psy/_essentials") # set to current directory
# list.files() # all files + folders in current directory
fileName <- "explore.Rmd"

## (c) Packages: ----- 
library(knitr)
library(rmdformats)
library(tidyverse)

## (d) Global options: ----- 
options(max.print = "75")
opts_chunk$set(echo = TRUE,
	             cache = TRUE,
               prompt = FALSE,
               tidy = FALSE,
               collapse = TRUE, # set TRUE in answers 
               comment = "#>",
               message = FALSE,
               warning = FALSE,
               ## Default figure options:
               fig.width = 7, 
               fig.asp = .618, # golden ratio
               out.width = "75%",
               fig.align = "center"
               )
opts_knit$set(width = 75)

## (e) Custom functions: ----- 
source(file = "~/Desktop/stuff/Dropbox/_code/R/_teachR/ds4psy/R/custom_functions.R")
```

# Introduction

This file contains **essential commands** from [Chapter 7: Exploratory data analysis](https://r4ds.had.co.nz/exploratory-data-analysis.html) of the textbook [r4ds](http://r4ds.had.co.nz) and corresponding examples and exercises. 
A command is considered "essential" when you really need to _know_ it and need to know _how to use_ it to succeed in this course. 

<!-- Table with links: -->

All [ds4psy](http://rpository.com/ds4psy/) essentials so far: 

Nr. | Topic       |
---:|:------------| 
0.  | [Syllabus](http://rpository.com/ds4psy/) | 
1.  | [Basic R concepts and commands](http://rpository.com/ds4psy/essentials/basics.html) | 
2.  | [Visualizing data](http://rpository.com/ds4psy/essentials/visualize.html) | 
3.  | [Transforming data](http://rpository.com/ds4psy/essentials/transform.html) |
4.  | **Exploring data (EDA)** |
+.  | [Datasets](http://rpository.com/ds4psy/essentials/datasets.html) | 

<!--
Nr. | Topic       |
---:|:------------| 
0.  | [Syllabus](http://rpository.com/ds4psy/) | 
1.  | [Basic R concepts and commands](http://rpository.com/ds4psy/essentials/basics.html) | 
2.  | [Visualizing data](http://rpository.com/ds4psy/essentials/visualize.html) | 
3.  | [Transforming data](http://rpository.com/ds4psy/essentials/transform.html) |
4.  | [Exploring data (EDA)](http://rpository.com/ds4psy/essentials/explore.html) | 
5.  | [Creating and using tibbles](http://rpository.com/ds4psy/essentials/tibble.html) |
6.  | [Tidying data](http://rpository.com/ds4psy/essentials/tidy.html) |
+.  | [Datasets](http://rpository.com/ds4psy/essentials/datasets.html) | 
-->

## Course coordinates

<!-- uni.kn logo and link to SPDS: -->  
<!-- ![](./inst/pix/uniKn_logo.png) --> 
<a href="https://www.spds.uni-konstanz.de/">
<img src = "../inst/pix/uniKn_logo.png" alt = "spds.uni.kn" align = "right" width = "300" style = "width: 300px; float: right; border:20;"/>
<!-- <img src = "./inst/pix/uniKn_logo_s.png" alt = "spds.uni.kn" style = "float: right; border:20;"/> --> 
</a>

* Taught at the [University of Konstanz](https://www.uni-konstanz.de/) by [Hansjörg Neth](http://neth.de/) (<h.neth@uni.kn>,  [SPDS](https://www.spds.uni-konstanz.de/), office D507).
* Winter 2018/2019: Mondays, 13:30--15:00, C511. 
* Links to current [course syllabus](http://rpository.com/ds4psy/) | [ZeUS](https://zeus.uni-konstanz.de/hioserver/pages/startFlow.xhtml?_flowId=detailView-flow&unitId=5101&periodId=78&navigationPosition=hisinoneLehrorganisation,examEventOverviewOwn) |  [Ilias](https://ilias.uni-konstanz.de/ilias/goto_ilias_uni_crs_809936.html) 

## Preparations

Create an R script (`.R`) or an R-Markdown file (`.Rmd`) and load the R packages of the `tidyverse`. (Hint: Structure your script by inserting spaces, meaningful comments, and sections.) 

```{r layout_template, echo = TRUE, eval = FALSE}
## Exploring data (EDA) | ds4psy
## 2018 11 26
## ----------------------------

## Preparations: ----------

library(tidyverse)

## 1. Topic: ----------

# etc.

## End of file (eof). ----------  
```


# Exploring data

## Introduction

In the following, we refine and use what we have learned so far. Essentially, this session combines what we have learned about `ggplot2` (in [Chapter 3: Data visualization](http://r4ds.had.co.nz/data-visualisation.html)) and about `dplyr` (in [Chapter 5: Data transformation](https://r4ds.had.co.nz/transform.html)) to explore datasets.  

Important concepts in this session include: 

- missing values (`NA`)  
- different measurement levels of variables (e.g., categorical vs. continuous)  

See [Chapter 7: Exploratory data analysis (EDA)](http://r4ds.had.co.nz/exploratory-data-analysis.html) and the links provided below for more detailed information. 

## What is EDA? 

The goal and purpose of _exploratory data analysis_ (EDA) is to gain an overview of a dataset. This includes an idea of its dimensions and the number and types of variables contained in the data, but also a more detailed idea of the distribution of variables, their potential relations to each other, and potential problems (e.g., missing values or outliers). 

When using the tools provided by the `tidyverse`, the fastest way to gain insights into a dataset is a series of `dplyr` calls and `ggplot2` graphs. However, creating good graphs is both an art and a craft. The key to creating good graphs requires answering 2 sets of questions: 

1. Knowing the _intended type of plot_. This includes answering _functional_ questions like 

    - What is the _goal_ or _purpose_ of this plot?
    - What are _possible_ plot types for this purpose? 
    - Which of these would be the most _appropriate_ plot here? 
    
2. Knowing the _number_ and _type_ of variables to be plotted. This includes answering _data-related_ questions like 

    - How many variables are to be plotted and how are they mapped to dimensions and aesthetics?  
    - Are these variables categorical or continuous?  
    - Do some variables control or qualify (e.g., group) the values of others?   

Even when these questions are answered, creating beautiful and informative graphs with `ggplot` requires dedicated practice, experience, and trial-and-error experimentation. In addition, an new dataset is rarely in a condition and shape to directly allow plotting. Instead, we typically have to interleave commands for plotting and transforming data to wrangle variables into specific shapes or types. Thus, calls to `ggplot2` usually occur in combination with other `tidyverse` commands (stemming from `dplyr`, `forcats`, `tidyr`, `readr`, `tibble`, etc.). 

What needs to be done in any specific case depends on the details of the data and your current goals. Also, there is no pre-defined end to an EDA and no clear boundary between the processes of exploration and the confirmation (or falsification) of expectations. Typically, social scientists use EDA to check and understand a dataset, before using statistics to test specific hypotheses.  

While any actual EDA is tailored to specific features of the data and current research goals, the following sections highlight some common themes that occur in most cases. We illustrate these steps in the context of a dataset that was collected to measure the short- and long-term effects of positive psychology interventions (see [Dataset: Positive Psychology](http://rpository.com/ds4psy/essentials/datasets.html#positive-psychology) for details).^[The participant part of this data has been used as `p_info` in the previous sessions.]

# Principles and practices

In the following, we will explain some principles that endorse and promote the ideal of _transparent data analysis_ and _reproducible research_. While such practices are indispensable when working in a team of colleagues and the wider scientific community, organizing your workflow in a more consistent fashion is also beneficial for your future self and other projects.

## Starting well

Before embarking on any actual analysis, we should pay tribute to 2 principles that seem so simple that it's easy to overlook their benefits: 

- **Principle 1:** Structure and comment your analysis.

While adhering to this principle may seem unnecessary or trivial at first, it gets more important as analyses get longer and more complicated (e.g., distributed over multiple datasets and scripts). A consistent document structure, transparent object names, and clear and informative comments are indispensable when sharing your data or scripts with others. Comments structure a longer document into parts and briefly explain the content of each part (_what_), but should primarily focus on the goals and reasons for your decisions (i.e., explain _why_, rather than _how_ you did something).  

- **Principle 2:** Start with a clean slate and explicitly load all data and all packages required in this analysis.

Although RStudio IDE provides options for saving your workspace and for loading data or packages by clicking buttons or checking boxes, doing so renders the process of your analysis intransparent for anyone not observing all your actions. To make sure that others and yourself can repeat the same sequence of steps tomorrow or next year, it is advisable to always start with a clean slate and explicitly state which data and packages are required for the current analysis (unless there are good reasons to deviate from them):^[Actually, listing _everything_ required to execute a file can get quite excessive (check out `sessionInfo()` or the `session_info` and `package_info` functions of `devtools`, in case you're interested, and consider using the `packrat` package in case you want to preserve or share your current setup). Hence, most people only explicitly list and load non-standard packages (in their current version).]

```{r clean_and_load}
# Housekeeping:
rm(list = ls())  # cleans ALL objects in current R environment (without asking for confirmation)!

# Load packages:
library(tidyverse)
library(knitr)
library(rmarkdown)

# Load data file(s):
posPsy_wide <- readr::read_csv(file = "http://rpository.com/ds4psy/data/posPsy_data_wide.csv")
dim(posPsy_wide)  # 295 cases x 294 variables

# Other customizations:
seeblau <- rgb(0, 169, 224, names = "seeblau", maxColorValue = 255)  # seeblau.4 of uni.kn color scheme 
```

- **Principle 3:** Make copies (and copies of copies) of your data.  

It is only human to make occasonal errors. To make sure that errors are not too costly, a good habit is to occasionally save intermediate steps. This refers to both your data files and your scripts for analyzing them. Although it may be a good idea to always keep a ``current master version'' of a data file, it is also advisable to occasionally copy your current data and then work on the copy (e.g., before trying out some unfamiliar analysis or command). In R, creating copies and then working on them is very easy --- and can even save yourself from repeatedly typing complicated object names. Most importantly, when working on a copy of your data, you can always recover the last sound version if things go terribly wrong:  

```{r copy_data_kill_recover}
df <- posPsy_wide  # copy data (and simplify name)
dim(df)            # 295 cases x 294 variables

sum(is.na(df))  # 37440 missing values
df$new <- NA    # create a new column with NA values
df$new          # check the new column
df <- NA        # create a new column with NA values

# Ooops... 
df  # looks like we accidentally killed our data!  

# But do not despair:
df <- posPsy_wide  # Here it is again: 
dim(df)            # 295 cases x 294 variables
```

During a long and complicated analysis, it is advisable to save an external copy of your current data when having reached an important intermediate step. While there are many different formats in which data files can be stored, a good option for most files is `csv` (comma-separated-values), which can easily be read by most humans and machines. Importantly, always verify that the external copy preserves the key information contained in your current original:  

```{r write_and_reread_csv_data}
# Write out current data (in csv-format):
write_csv(df, path = "my_precious_data.csv")

# Re-read external data (into a different object):
df_2 <- read_csv(file = "my_precious_data.csv")

# Verify that original and copy are identical:
all.equal(df, df_2)
```


+++ here now +++ 


## Screening data

Checking basic properties, the validity of cases and values, and the distributions of variables. 

### Basics

Dimensions, 
types of variables and values, 
number, means, and ranges of values.

### Missing values

Missing values are `NA`. Note that `NA` is different from `NULL`: `NULL` represents the null object (i.e., something is undefined). By contrast, `NA` means that some value is absent.

```{r}
is.null(NULL) # TRUE
is.null(NA)   # FALSE

is.na(NA)   # TRUE
is.na(NULL) # 0 (NULL)

```


- counting missing values
- replacing instances of "-77", "-99", etc.


### Outliers

Detecting outliers by checking distributions of raw values and descriptive statistics.

Definition depends on content (see exercise). 

- mean & distribution 
- quartiles

Detection by graphs: 

- histograms
- trend line (e.g. `geom_smooth`) 
- scatterplots
- box plots


### Handling invalid cases

- Filtering observations (in rows)
- Deleting or replacing values (in columns)



## Understanding data

Using plots to visualize data

### Typical and a-typical values:

##### Histograms

- We covered histograms in [Visualizing data](http://rpository.com/ds4psy/essentials/visualize.html). 


### Relations between variables


#### 2 categorical variables


#### 1 categorical and 1 continuous variable

##### Bar plots

We covered bar plots in [Visualizing data](http://rpository.com/ds4psy/essentials/visualize.html). 

##### Box plots
##### Violin plots
##### Pirate plots


#### 2 continuous variables

- We covered scatterplots in [Visualizing data](http://rpository.com/ds4psy/essentials/visualize.html). 

### More than 2 variables

##### Tile plots
##### Size plots



## OLDER

Basic plot types: 

### Histograms

A histogram shows counts of the values of 1 (typically continuous) variable. This is useful for evaluating the distribution of the variable:

```{r histograms}
library(ggplot2)
 
# Create data: 
tb <- tibble(iq = rnorm(n = 1000, mean = 100, sd = 15))
 
# Basic histogram:
ggplot(tb) + 
  geom_histogram(aes(x = iq), binwidth = 5)

# Pimped histogram: 
ggplot(tb) + 
  geom_histogram(aes(x = iq), binwidth = 5, 
                 fill = "gold", color = "black") +
  labs(title = "Histogram", x = "IQ values", y = "Frequency in sample (n)",
       caption = "[Using random iq data.]") +
  theme_classic()
```

More on histograms: 

- <https://www.r-graph-gallery.com/histogram/>

### Scatterplots

A scatterplot shows the relationship between 2 (typically continuous) variables:

```{r scatterplots}
# Data:
ir <- as_tibble(iris)
ir

# Basic scatterplot:
ggplot(ir) +
  geom_point(aes(x = Petal.Length, y = Petal.Width, color = Species, shape = Species))

# Using 3 different facets:
ggplot(ir) +
  geom_point(aes(x = Petal.Length, y = Petal.Width, color = Species)) +
  facet_wrap(~Species)

# Pimped scatterplot:
ggplot(ir) +
  geom_point(aes(x = Petal.Length, y = Petal.Width, fill = Species), pch = 21, color = "black", size = 2, alpha = 1/2) +
  facet_wrap(~Species) +
  # coord_fixed() + 
  labs(title = "Scatterplot", x = "Length of petal", y = "Width of petal",
       caption = "[Using iris data.]") + 
  theme_bw() +
  theme(legend.position = "none")
```

More on scatterplots: 

- <https://www.r-graph-gallery.com/scatterplot/>


### Bar plots

Another common type of plot shows the values (across different levels of some variable as the height of bars. As this plot type can use both categorical or continuous variables, it turns out to be surprisingly complex to create good bar charts. To us get started, here are only a few examples: 

#### Counts of cases

By default, `geom_bar` computes summary statistics of the data. When nothing else is specified, `geom_bar` _counts_ the number or frequency of values (i.e., `stat = "count"`) and maps this count to the `y` (i.e., `y = ..count..`): 

```{r bar_plot_count}
library(ggplot2)

## Data: 
ggplot2::mpg

# (1) Count number of cases by class: 
ggplot(mpg) + 
  geom_bar(aes(x = class))

# (b) is the same as: 
ggplot(mpg) + 
  geom_bar(aes(x = class, y = ..count..))

# (c) is the same as:
ggplot(mpg) + 
  geom_bar(aes(x = class), stat = "count")

# (d) is the same as:
ggplot(mpg) + 
  geom_bar(aes(x = class, y = ..count..), stat = "count")

# (e) pimped version:
ggplot(mpg) + 
  geom_bar(aes(x = class, fill = class), 
           # stat = "count", 
           color = "black") + 
  labs(title = "Counts of cars by class",
       x = "Class of car", y = "Frequency") + 
  scale_fill_brewer(name = "Class:", palette = "Blues") + 
  theme_bw()
```

**Practice:** Plot the _number_ or _frequency of cases_ in the `mpg` data by `cyl` (in at least 3 different ways). 

```{r bar_plot_count_ex, echo = FALSE, eval = FALSE}
# (2) Count number of cases by cylinders: 
ggplot(mpg) + 
  geom_bar(aes(x = cyl))

ggplot(mpg) + 
  geom_bar(aes(x = cyl, y = ..count..))

ggplot(mpg) + 
  geom_bar(aes(x = cyl), stat = "count")


# pimped version:
ggplot(mpg) + 
  geom_bar(aes(x = cyl, fill = as.factor(cyl)), 
           stat = "count",
           color = "black") + 
  labs(title = "Counts of cars by class",
       x = "Cylinders", y = "Frequency") + 
  scale_fill_brewer(name = "Cylinders:", palette = "Spectral") + 
  # coord_flip() + 
  theme_bw()
```


#### Proportion of cases

An alternative to showing the count or frequency of cases is showing the corresponding _proportion_ of cases: 

```{r bar_plot_prop}
library(ggplot2)

## Data: 
ggplot2::mpg

# (1) Proportion of cases by class: 
ggplot(mpg) + 
  geom_bar(aes(x = class, y = ..prop.., group = 1))

# is the same as: 
ggplot(mpg) + 
  geom_bar(aes(x = class, y = ..count../sum(..count..)))
```

**Practice:** Plot the _proportion of cases_ in the `mpg` data by `cyl` (in at least 3 different ways). 


#### Bar plots of existing values

A common difficulty occurs when the table to plot already contains the values to be shown as bars. 
As there is nothing to be computed in this case, we need to specify `stat = "identity"` for `geom_bar` (to override its default of `stat = "count"`). 

For instance, let's plot a bar chart that shows the election data from the following tibble `de`:

```{r election_data, echo = FALSE, eval = TRUE}
library(knitr)
library(tidyverse)

## (a) Create a tibble of data: 
de_org <- tibble(
    party = c("CDU/CSU", "SPD", "Others"),
    share_2013 = c((.341 + .074), .257, (1 - (.341 + .074) - .257)), 
    share_2017 = c((.268 + .062), .205, (1 - (.268 + .062) - .205))
  )
de_org$party <- factor(de_org$party, levels = c("CDU/CSU", "SPD", "Others"))  # optional
# de_org

## Check that columns add to 100:
# sum(de_org$share_2013)  # => 1 (qed)
# sum(de_org$share_2017)  # => 1 (qed)

## (b) Converting de into a tidy data table:
de <- de_org %>%
  gather(share_2013:share_2017, key = "election", value = "share") %>%
  separate(col = "election", into = c("dummy", "year")) %>%
  select(year, party, share)
kable(de)
```

1. A version with 2 x 3 separate bars (using `position = "dodge"`): 

```{r bar_plot_stat_identity_dodge}
## Data: ----- 
de  # => 6 x 3 tibble

## Note that year is of type character, which could be changed by:
# de$year <- parse_integer(de$year)

## (1) Bar chart with  side-by-side bars (dodge): ----- 

## (a) minimal version: 
bp_1 <- ggplot(de, aes(x = year, y = share, fill = party)) +
  ## (A) 3 bars per election (position = "dodge"):  
  geom_bar(stat = "identity", position = "dodge", color = "black") # 3 bars next to each other
bp_1

## (b) Version with text labels and customized colors: 
bp_1 + 
  ## pimping plot: 
  geom_text(aes(label = paste0(round(share * 100, 1), "%"), y = share + .01), 
            position = position_dodge(width = 1), 
            fontface = 2, color = "black") + 
  # Some set of high contrast colors: 
  scale_fill_manual(name = "Party:", values = c("black", "red3", "gold")) + 
  # Titles and labels: 
  labs(title = "Partial results of the German general elections 2013 and 2017", 
       x = "Year of election", y = "Share of votes", 
       caption = "Data from www.bundeswahlleiter.de.") + 
  # coord_flip() + 
  theme_bw()
```

2. A version with 2 bars with 3 segments (using `position = "stack"`): 

```{r bar_plot_stat_identity_stack}
## Data: ----- 
de  # => 6 x 3 tibble

## (2) Bar chart with stacked bars: -----  

## (a) minimal version: 
bp_2 <- ggplot(de, aes(x = year, y = share, fill = party)) +
  ## (B) 1 bar per election (position = "stack"):
  geom_bar(stat = "identity", position = "stack") # 1 bar per election
bp_2

## (b) Version with text labels and customized colors: 
bp_2 +   
  ## Pimping plot: 
  geom_text(aes(label = paste0(round(share * 100, 1), "%")), 
            position = position_stack(vjust = .5),
            color = rep(c("black", "white", "white"), 2), 
            fontface = 2) + 
  # Some set of high contrast colors: 
  scale_fill_manual(name = "Party:", values = c("black", "red3", "gold")) + 
  # Titles and labels: 
  labs(title = "Partial results of the German general elections 2013 and 2017", 
       x = "Year of election", y = "Share of votes", 
       caption = "Data from www.bundeswahlleiter.de.") + 
  # coord_flip() + 
  theme_classic()
```

#### Bar plots with error bars

It is typically a good idea to show some measure of variability (e.g., the standard deviation, standard error, confidence interval, etc.) to any bar plots. 
There is an entire range of geoms that draw error bars: 

```{r bar_plot_error_bar}
## Create data to plot: ----- 
n_cat <- 6
set.seed(101)

data <- tibble(
  name = LETTERS[1:n_cat],
  value = sample(seq(25, 50), n_cat),
  sd = rnorm(n = n_cat, mean = 0, sd = 8))
data

## Error bars: -----

## x-aesthetic only:

# (a) errorbar: 
ggplot(data) +
    geom_bar(aes(x = name, y = value), stat = "identity", fill = seeblau) +
    geom_errorbar(aes(x = name, ymin = value - sd, ymax = value + sd), 
                  width = 0.4, color = "orange", alpha = 1, size = 1.0)

# (b) linerange: 
ggplot(data) +
    geom_bar(aes(x = name, y = value), stat = "identity", fill = "olivedrab3") +
    geom_linerange(aes(x = name, ymin = value - sd, ymax = value + sd), 
                   color = "firebrick", alpha = 1, size = 2.5)

## Additional y-aesthetic: 

# (c) crossbar:
ggplot(data) +
    geom_bar(aes(x = name, y = value), stat = "identity", fill = "tomato4") +
    geom_crossbar(aes(x = name, y = value, ymin = value - sd, ymax = value + sd), 
                  width = 0.3, color = "sienna1", alpha = 1, size = 1.0)

# (d) pointrange: 
ggplot(data) +
    geom_bar(aes(x = name, y = value), stat = "identity", fill = "burlywood4") +
    geom_pointrange(aes(x = name, y = value, ymin = value - sd, ymax = value + sd), 
                    color = "gold", alpha = 1.0, size = 1.2)
```

More on barplots:

- <https://www.r-graph-gallery.com/barplot/>. 

### Drawing curves and lines

**ToDo:**

- adding trendlines
- lines of data (e.g., means)

### Box plots

**ToDo:** 

- show medians, quartiles, distribution, and outliers



### Improving plots

Most default plots can be improved by fine-tuning their visual appearance. 
Popular levers for "pimping" plots include: 

- colors: can be set withing geoms (variable when inside `aes(...)`, fixed outside), choosing or designing specific color scales;  
- labels: `labs(...)` allows setting titles, captions, axis labels, etc.;  
- legends: can be (re-)moved or edited;  
- themes: can be selected or modified.  


### Related plots and packages

`ggplot2` comes with a large variety of geoms. Nevertheless, we sometimes want to show or do something that is not included in the standard package. [Chapter 7: Exploratory data analysis](http://r4ds.had.co.nz/exploratory-data-analysis.html) goes beyond standard `ggplot` geoms by touching on `geom_hex` (from the `hexbin` package) and `geom_beeswarm` and `geom_quasirandom` (from the `ggbeeswarm` package). When looking for new forms of visual expression, web sites like 

- [Data Visualization Catalogue](https://datavizcatalogue.com)
- [Google charts](https://developers.google.com/chart/)
- [R-graph gallery](http://www.r-graph-gallery.com)

can inspire and provide many interesting pointers. The site 

- [ggplot2-exts.org](https://www.ggplot2-exts.org/) 

also provides valuable resources for `ggplot` users, as it shows packages specifically designed to work with `ggplot2`. In the following, we illustrate the package `ggalluvial` that allows showing the transitions between categorical data. 

#### Example 1: Alluvial plot

```{r alluvial_plots_1, fig.width = 6, fig.height = 8}
# Preparations: 
library(tidyverse)
# install.packages("ggalluvial")
library(ggalluvial)

# Example 1 (adapted from vignette): ----- 

as_tibble(as.data.frame(UCBAdmissions))
is_alluvial(as.data.frame(UCBAdmissions), logical = FALSE, silent = TRUE)

ggplot(as.data.frame(UCBAdmissions),
       aes(weight = Freq, axis1 = Gender, axis2 = Dept)) +
  geom_alluvium(aes(fill = Admit), width = .10, color = "grey10") +
  geom_stratum(width = .10, 
               fill = c("firebrick", "steelblue4", "grey10", "grey80", "grey30", "grey50", "grey70", "grey20"), 
               color = "grey10") +
  geom_label(stat = "stratum", label.strata = TRUE) +
  scale_x_continuous(breaks = 1:2, labels = c("Gender", "Department")) +
  # scale_fill_brewer(type = "qual", palette = "Set2") +
  scale_fill_manual(name = "Admissions:", values = c("forestgreen", "gold2")) + 
  ggtitle("UC Berkeley admissions and rejections") +
  theme_light()
```

An important feature of these diagrams is the meaningfulness of the vertical axis: No gaps are inserted between the strata, so the total height of the diagram reflects the cumulative weight of the observations.^[This is different in _Sankey diagrams_, shown <https://developers.google.com/chart/interactive/docs/gallery/sankey>.]


#### Example 2: Parallel set diagram 

```{r alluvial_plots_2, fig.width = 7, fig.height = 7}
# Preparations: 
library(ggalluvial)

# Example 2 (adapted from vignette): ----- 

as_tibble(as.data.frame(Titanic))

ggplot(as.data.frame(Titanic),
       aes(weight = Freq,
           axis1 = Survived, axis2 = Sex, axis3 = Class)) +
  geom_alluvium(aes(fill = Class),
                width = 0, knot.pos = 0, reverse = FALSE) +
  guides(fill = FALSE) +
  geom_stratum(width = 1/12, reverse = FALSE) +
  geom_text(stat = "stratum", label.strata = TRUE, reverse = FALSE) +
  scale_x_continuous(breaks = 1:3, labels = c("Survived", "Gender", "Class")) +
  coord_flip() +
  ggtitle("Titanic survival by class and gender (1)") +
  scale_fill_brewer(type = "qual", palette = "Dark2") +
  theme_bw()

# Switching order of axes (to put Survived in the middle):
# Fill alluvium by Survived: 
ggplot(as.data.frame(Titanic),
       aes(weight = Freq,
           axis1 = Sex, axis2 = Survived, axis3 = Class)) +
  geom_alluvium(aes(fill = Survived), # rather than Class
                width = 0, knot.pos = 0, reverse = FALSE) +
  guides(fill = FALSE) +
  geom_stratum(width = 1/12, reverse = FALSE) +
  geom_text(stat = "stratum", label.strata = TRUE, reverse = FALSE) +
  scale_x_continuous(breaks = 1:3, labels = c("Gender", "Survived", "Class")) +
  coord_flip() +
  ggtitle("Titanic survival by class and gender (2)") +
  # scale_fill_brewer(type = "qual", palette = "Set1") +
  scale_fill_manual(name = "Survival:", values = c("black", "forestgreen")) +
  theme_bw()

# Fill alluvium by gender:
ggplot(as.data.frame(Titanic),
       aes(weight = Freq,
           axis1 = Class, axis2 = Survived, axis3 = Sex)) +
  geom_alluvium(aes(fill = Sex), 
                width = 0, knot.pos = 0, reverse = FALSE) +
  guides(fill = FALSE) +
  geom_stratum(width = 1/12, reverse = FALSE) +
  geom_text(stat = "stratum", label.strata = TRUE, reverse = FALSE) +
  scale_x_continuous(breaks = 1:3, labels = c("Class", "Survived", "Gender")) +
  coord_flip() +
  ggtitle("Titanic survival by class and gender (3)") +
  # scale_fill_brewer(type = "qual", palette = "Paired") +
  scale_fill_manual(values = c("steelblue", "firebrick")) + 
  theme_bw()
```

#### Example 3: Data in long format

```{r alluvial_plots_3, fig.width = 8, fig.height = 5}
# Preparations: 
library(ggalluvial)

# Example 3 (adapted from vignette): ----- 

?majors
data(majors)
as_tibble(majors) # illustrating lode format 
majors$curriculum <- as.factor(majors$curriculum)

ggplot(majors,
       aes(x = semester, stratum = curriculum, alluvium = student,
           fill = curriculum, label = curriculum)) +
  scale_fill_brewer(type = "qual", palette = "Pastel2") +
  geom_flow(stat = "alluvium", 
            lode.guidance = "rightleft",
            color = "darkgray") +
  geom_stratum() +
  theme(legend.position = "right") + # "bottom" "top"
  ggtitle("Student curricula across several semesters") +
  theme_light()
```

See the packages `circlize`, `ggforce`, and `ggparallel` for other types of transition plots. 


# Exercises

**Ideas:**

Plot same plot _twice_: 
    1. from a lot of raw data and 
    2. from much leaner table of aggregated data.
    
+++ here now +++


# More on data visualization / EDA

- study `vignette("ggplot")` and the documentation for `ggplot` and various geoms (e.g., `geom_`);
- study <https://ggplot2.tidyverse.org/reference/> and its examples; 
- see the [cheat sheet on data visualization](https://www.rstudio.com/resources/cheatsheets/); 
- read [Chapter 3: Data visualization](http://r4ds.had.co.nz/data-visualisation.html) and [Chapter 7: Exploratory data analysis (EDA)](http://r4ds.had.co.nz/exploratory-data-analysis.html) and complete their exercises. 


# Conclusion 

<!-- Table with links: -->

All [ds4psy](http://rpository.com/ds4psy/) essentials: 

Nr. | Topic       |
---:|:------------| 
0.  | [Syllabus](http://rpository.com/ds4psy/) | 
1.  | [Basic R concepts and commands](http://rpository.com/ds4psy/essentials/basics.html) | 
2.  | [Visualizing data](http://rpository.com/ds4psy/essentials/visualize.html) | 
3.  | [Transforming data](http://rpository.com/ds4psy/essentials/transform.html) |
4.  | **Exploring data (EDA)** | 
+.  | [Datasets](http://rpository.com/ds4psy/essentials/datasets.html) |  

<!--
Nr. | Topic       |
---:|:------------| 
0.  | [Syllabus](http://rpository.com/ds4psy/) | 
1.  | [Basic R concepts and commands](http://rpository.com/ds4psy/essentials/basics.html) | 
2.  | [Visualizing data](http://rpository.com/ds4psy/essentials/visualize.html) | 
3.  | [Transforming data](http://rpository.com/ds4psy/essentials/transform.html) |
4.  | [Exploring data (EDA)](http://rpository.com/ds4psy/essentials/explore.html) | 
5.  | [Creating and using tibbles](http://rpository.com/ds4psy/essentials/tibble.html) |
6.  | [Tidying data](http://rpository.com/ds4psy/essentials/tidy.html) |
+.  | [Datasets](http://rpository.com/ds4psy/essentials/datasets.html) | 
-->

```{r colophon, echo = FALSE, eval = FALSE}
# This document was built using:

# sessionInfo()
# devtools::session_info()
# devtools::package_info()
```


[Last update on `r Sys.time()` by [hn](http://neth.de/).]  

<!-- eof. --> 